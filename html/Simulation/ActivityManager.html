<!doctype html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta content="width=device-width, initial-scale=1, minimum-scale=1" name="viewport"/>
    <meta content="pdoc 0.9.2" name="generator"/>
    <title>Simulation.ActivityManager API documentation</title>
    <meta content="" name="description"/>
    <link as="style" crossorigin href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css"
          integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" rel="preload stylesheet">
    <link as="style" crossorigin
          href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css"
          integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" rel="preload stylesheet">
    <link as="style" crossorigin href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css"
          rel="stylesheet preload">
    <style>
        :root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}
    </style>
    <style media="screen and (min-width: 700px)">
        @media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}
    </style>
    <style media="print">
        @media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}
    </style>
    <script crossorigin defer integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8="
            src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js"></script>
    <script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
    <article id="content">
        <header>
            <h1 class="title">Module <code>Simulation.ActivityManager</code></h1>
        </header>
        <section id="section-intro">
            <details class="source">
                <summary>
                    <span>Expand source code</span>
                </summary>
                <pre><code class="python">import datetime as dt
import math
import random
import sys
from os.path import dirname
from subprocess import check_call

import matplotlib.image as mpimg
import matplotlib.pyplot as plt
import networkx as nx
import numpy as np
import pandas as pd
import seaborn as sns
from statsmodels.tsa.statespace.varmax import VARMAX

sys.path.append(dirname(__file__))

from Simulation.MacroActivity import MacroActivity


def forecast_durations(duration_data, train_ratio, nb_periods_to_forecast):
    &#34;&#34;&#34;
    forecast the activities duration
    :param train_ratio:
    :param last_time_window_id:
    :param nb_periods_to_forecast:
    :param display:
    :return: Two dict like object {label: r2_score}
    &#34;&#34;&#34;

    duration_dist_errors = pd.DataFrame(columns=[&#39;label&#39;, &#39;mean_error&#39;, &#39;std_error&#39;])

    # Fill history count df until last time window registered

    last_time_window_id = int(duration_data.tw_id.max())

    forecast_df = pd.DataFrame(columns=[&#39;tw_id&#39;, &#39;mean&#39;, &#39;std&#39;])

    forecast_df.tw_id = np.arange(last_time_window_id, last_time_window_id + nb_periods_to_forecast)

    data = duration_data[[&#39;mean&#39;, &#39;std&#39;]]

    train_size = int(len(data) * train_ratio)

    train, test = data[:train_size], data[train_size:]

    test_size = test.shape[0]

    model = VARMAX(train.values, order=(2, 2), enforce_stationarity=True, enforce_invertibility=False)

    try:
        model = model.fit(disp=False)
    except np.linalg.LinAlgError as e:
        return None

    raw_forecast = model.forecast(test_size + nb_periods_to_forecast)

    index = np.arange(train_size + 1, train_size + 1 + test_size + nb_periods_to_forecast)
    raw_forecast = pd.DataFrame(raw_forecast, index, [&#39;mean&#39;, &#39;std&#39;])

    validation_forecast = raw_forecast[:test_size]
    # nmse_error_mean = mean_squared_error(test[&#39;mean&#39;], validation_forecast[&#39;mean&#39;]) / np.mean(test[&#39;mean&#39;])
    # nmse_error_std = mean_squared_error(test[&#39;std&#39;], validation_forecast[&#39;std&#39;]) / np.mean(test[&#39;std&#39;])

    # Forecast to use
    forecasts = raw_forecast[test_size:]

    # Replace all negative values by 0
    forecasts[forecasts &lt; 0] = 0

    return forecasts


class ActivityManager:
    &#34;&#34;&#34;
    Manage the macro-activities created in the time windows
    &#34;&#34;&#34;

    # OBSOLESCENCE_DURATION_DAYS = 60

    def __init__(self, name, period, time_step, tep, window_size=None, max_no_news=None, dynamic=False, ):
        &#34;&#34;&#34;
        Initialisation of the Manager
        :param name:
        :param period:
        :param time_step: Time discretization parameter
        &#34;&#34;&#34;
        self.name = name
        self.period = period
        self.tep = tep
        self.time_step = time_step
        self.window_size = window_size
        self.OBSOLESCENCE_DURATION_DAYS = max_no_news
        self.discovered_episodes = []  # All the episodes discovered until then
        self.activity_objects = {}  # The Activity/MacroActivity objects
        self.mixed_occurrences = pd.DataFrame(columns=[&#39;date&#39;, &#39;end_date&#39;, &#39;label&#39;, &#39;tw_id&#39;])
        self.last_time_window_id = 0
        self.dynamic = dynamic
        self.nb_new_episodes = []
        self.labels_duration_dist = {}

    def update(self, episode, occurrences, events, time_window_id=0, display=False):
        &#34;&#34;&#34;
        Update the Macro-Activity Object related to the macro-activity discovered if they already exist OR create a
        new Object
        :param episode:
        :param occurrences:
        :param events:
        :param time_window_id:
        :return:
        &#34;&#34;&#34;

        set_episode = frozenset(episode)

        if set_episode not in self.discovered_episodes:  # Create a new Macro-Activity Object
            activity_object = MacroActivity(episode=episode, period=self.period, time_step=self.time_step, tep=self.tep)

            self.discovered_episodes.append(set_episode)
            self.activity_objects[set_episode] = activity_object

        activity_object = self.activity_objects[set_episode]
        activity_object.add_time_window(occurrences=occurrences, events=events,
                                        time_window_id=time_window_id, display=False)

        occurrences[&#39;label&#39;] = [str(set_episode) for _ in range(len(occurrences))]
        occurrences[&#39;tw_id&#39;] = time_window_id

        self.mixed_occurrences = pd.concat(
            [self.mixed_occurrences, occurrences[[&#39;date&#39;, &#39;end_date&#39;, &#39;label&#39;, &#39;tw_id&#39;]]]).drop_duplicates(keep=False)

        self.mixed_occurrences.sort_values([&#39;date&#39;], inplace=True)

        self.last_time_window_id = time_window_id

        if self.dynamic:
            self.obsolescence_check()

        self.nb_new_episodes.append(len(self.discovered_episodes))

    def get_macro_activity_from_name(self, set_episode):
        &#34;&#34;&#34;
        return the MacroActivity Object related to the episode
        :param set_episode:
        :return:
        &#34;&#34;&#34;

        # set_episode = frozenset(set_episode)

        return self.activity_objects[set_episode]

    def build_transition_matrix(self, time_window_id=0, display=False):
        &#34;&#34;&#34;
        Build a transition distance_matrix for all the available activities
        :return:
        &#34;&#34;&#34;

        data = self.mixed_occurrences[self.mixed_occurrences.tw_id == time_window_id].copy()
        labels = data.label.unique()

        data[&#39;next_label&#39;] = data[&#39;label&#39;].shift(-1)
        data.dropna(inplace=True)

        matrix = pd.DataFrame(columns=labels, index=labels)

        for i_label in labels:
            i_data = data[data.label == i_label]
            nb_i_occ = len(i_data)
            for j_label in labels:
                nb_j_occ = len(i_data[i_data.next_label == j_label])
                matrix.loc[i_label, j_label] = nb_j_occ / nb_i_occ

        if display:
            plot_markov_chain(matrix, labels, threshold=0.0)

        return matrix

    def obsolescence_check(self):
        &#34;&#34;&#34;
        Remove Macro-Activities which are obsoletes
        :return:
        &#34;&#34;&#34;

        obsoletes_episodes = []

        for set_episode, macro_activity_object in self.activity_objects.items():
            # Computer Macro-Activity Weight !!
            last_update_id = int(macro_activity_object.count_histogram.tw_id.max())

            nb_period_without_news = self.last_time_window_id - last_update_id

            if nb_period_without_news &gt; self.OBSOLESCENCE_DURATION_DAYS:
                obsoletes_episodes.append(set_episode)
                print(print(f&#34;{list(set_episode)} : OBSOLETE EPISODE&#34;))

        # DESTROY OBSOLETE EPISODES
        for set_episode in obsoletes_episodes:
            self.activity_objects.pop(set_episode)
            self.discovered_episodes.remove(set_episode)

    def build_forecasting_models(self, train_ratio, nb_periods_to_forecast, display=False, debug=False):
        &#34;&#34;&#34;
        Build forecasting models for Macro-Activity parameters
        :param debug:
        :param nb_periods_to_forecast:
        :param train_ratio: ratio of data used for training
        :param method: method used for the forecasting
        :param display:
        :return:
        &#34;&#34;&#34;

        ADP_error_df = pd.DataFrame(columns=[&#39;episode&#39;, &#39;rmse&#39;])
        duration_error_df = pd.DataFrame(columns=[&#39;episode&#39;, &#39;mean_rmse&#39;, &#39;std_rmse&#39;, &#39;label&#39;])

        # Build forecasting models
        i = 0

        for set_episode, macro_activity_object in self.activity_objects.items():
            print(f&#34;{list(set_episode)} : {macro_activity_object}&#34;)

            i += 1

            # ACTIVITY DAILY PROFILE FORECASTING
            # TODO : Enable ADP Forecasting

            # Fill

            ADP_error = macro_activity_object.forecast_history_count(train_ratio=train_ratio,
                                                                     last_time_window_id=self.last_time_window_id,
                                                                     nb_periods_to_forecast=nb_periods_to_forecast,
                                                                     display=debug)
            #
            # ADP_error_df.at[len(ADP_error_df)] = [tuple(set_episode), ADP_error]

            # ACTIVITIES DURATIONS FORECASTING
            # TODO : Monitor the error on forecasting models for duration
            for label in macro_activity_object.episode:
                macro_activity_object.duration_distrib[label] = self.labels_duration_dist[label]
            #
            # error_df = macro_activity_object.forecast_durations(train_ratio=train_ratio,
            #                                                     last_time_window_id=self.last_time_window_id,
            #                                                     nb_periods_to_forecast=nb_periods_to_forecast,
            #                                                     display=debug)
            #
            # for _, row in error_df.iterrows():
            #     duration_error_df.loc[len(duration_error_df)] = [tuple(set_episode), row[&#39;mean_error&#39;],
            #                                                      row[&#39;std_error&#39;], row[&#39;label&#39;]]

            # STOP HERE IF SINGLE-ACTIVITY
            # if len(set_episode) &lt; 2:
            #     break

            # EXECUTION ORDER FORECASTING
            # exec_order_error = macro_activity_object.forecast_execution_order(
            #     train_ratio=train_ratio, last_time_window_id=self.last_time_window_id,
            #     nb_periods_to_forecast=nb_periods_to_forecast, debug=debug)

            sys.stdout.write(
                &#34;\r{}/{} Macro-Activities Forecasting models done...&#34;.format(i, len(self.activity_objects)))
            sys.stdout.flush()
        sys.stdout.write(&#34;\n&#34;)

        if display:
            # Drop NAN
            ADPs_rmse = ADP_error_df.replace([np.inf, -np.inf], np.nan).dropna().rmse.values
            mean_durations_rmse = duration_error_df.replace([np.inf, -np.inf], np.nan).dropna().mean_rmse.values
            std_durations_rmse = duration_error_df.replace([np.inf, -np.inf], np.nan).dropna().std_rmse.values

            sns.kdeplot(ADPs_rmse, shade_lowest=False, shade=True, label=&#39;ADP Errors&#39;)
            plt.show()
            sns.kdeplot(mean_durations_rmse, shade_lowest=False, shade=True, label=&#39;Mean Duration Errors&#39;)
            sns.kdeplot(std_durations_rmse, shade_lowest=False, shade=True, label=&#39;STD Duration Errors&#39;)
            plt.show()

        # plt.hist(list(error_df.error.values))
        # plt.title(&#39;NMSE Distribution for all macro_activities forecasting models&#39;)
        # plt.show()

        return ADP_error_df, duration_error_df

    def build_forecasting_duration(self, dataset, train_ratio, nb_periods_to_forecast):
        &#34;&#34;&#34;
        :param train_ratio:
        :param nb_periods_to_forecast:
        :param display:
        :param debug:
        :return:
        &#34;&#34;&#34;
        time_window_duration = dt.timedelta(days=self.window_size)
        start_date = dataset.date.min().to_pydatetime()
        end_date = dataset.date.max().to_pydatetime() - time_window_duration

        dataset[&#39;duration&#39;] = dataset.end_date - dataset.date
        dataset[&#39;duration&#39;] = dataset[&#39;duration&#39;].apply(lambda x: x.total_seconds())

        labels = dataset.label.unique()

        labels_duration_dist = {}
        for label in labels:
            df = pd.DataFrame(columns=[&#39;tw_id&#39;, &#39;mean&#39;, &#39;std&#39;])
            labels_duration_dist[label] = df

        nb_tw = math.floor((end_date - start_date) / self.period)

        for tw_id in range(nb_tw):
            tw_start_date = start_date + dt.timedelta(days=tw_id)
            tw_end_date = tw_start_date + dt.timedelta(days=self.window_size)

            tw_dataset = dataset[(dataset.date &gt;= tw_start_date) &amp; (dataset.date &lt; tw_end_date)]

            for label in labels:
                mean_duration = np.mean(tw_dataset[tw_dataset.label == label][&#39;duration&#39;])
                std_duration = np.std(tw_dataset[tw_dataset.label == label][&#39;duration&#39;])

                df = labels_duration_dist[label]
                df.loc[tw_id] = [tw_id, mean_duration, std_duration]

        for label in labels:
            label_data = labels_duration_dist[label]

            forecast_data = forecast_durations(label_data, train_ratio, nb_periods_to_forecast)

            if forecast_data is None:
                forecast_data = pd.DataFrame(columns=[&#39;tw_id&#39;, &#39;mean&#39;, &#39;std&#39;])
                forecast_data[&#39;tw_id&#39;] = np.arange(len(label_data), len(label_data) + nb_periods_to_forecast)
                forecast_data[&#39;mean&#39;] = [label_data[&#39;mean&#39;].values[-1]] * nb_periods_to_forecast
                forecast_data[&#39;std&#39;] = [label_data[&#39;std&#39;].values[-1]] * nb_periods_to_forecast
                label_data = label_data.append(forecast_data, ignore_index=True)
            else:
                forecast_data[&#39;tw_id&#39;] = np.arange(len(label_data), len(label_data) + nb_periods_to_forecast)
                label_data = label_data.append(forecast_data, ignore_index=True)

            label_data.fillna(0, inplace=True)

        self.labels_duration_dist = labels_duration_dist

    def get_activity_daily_profiles(self, time_window_id=0):
        &#34;&#34;&#34;
        :param time_window_id:
        :return: a dict-like object of Macro-activities ADP
        &#34;&#34;&#34;

        macro_ADPs = {}

        activities_count_histogram = pd.DataFrame()

        for set_episode, macro_activity in self.activity_objects.items():
            count_histogram = macro_activity.get_count_histogram(time_window_id=time_window_id)
            count_histogram.drop([&#39;tw_id&#39;], axis=1, inplace=True)
            count_histogram.index = [set_episode]
            activities_count_histogram = activities_count_histogram.append(count_histogram)

        # No &#39;idle&#39; times
        # activities_count_histogram = activities_count_histogram.div(activities_count_histogram.sum(axis=0), axis=1)

        # With &#39;idle&#39; times

        div_array = activities_count_histogram.sum(axis=0)

        div_array = np.where(div_array &gt; self.window_size, div_array, self.window_size)

        activities_occ_probability = activities_count_histogram.div(div_array, axis=1)

        activities_occ_probability.fillna(0, inplace=True)

        for index, row in activities_occ_probability.iterrows():
            macro_ADPs[index] = row.values

        return macro_ADPs

    def simulate(self, start_date, end_date, idle_duration, time_window_id=0):
        &#34;&#34;&#34;
        Generate data between two dates using the model parameters for the selected time_window_id
        :param start_date: Start date of the simulation
        :param end_date: end date
        :param idle_duration: duration of a idle period of time
        :param time_window_id: selected time window id
        :return:
        &#34;&#34;&#34;

        simulated_dataset = pd.DataFrame(columns=[&#39;date&#39;, &#39;end_date&#39;, &#39;label&#39;])

        # Use
        previous_event = None
        current_date = start_date

        simulation_duration = (end_date - start_date).total_seconds()

        macro_ADPs = self.get_activity_daily_profiles(time_window_id=time_window_id)

        # transition_matrix = self.build_transition_matrix(time_window_id=time_window_id)

        current_time_window_id = time_window_id

        while current_date &lt; end_date:

            evolution_percentage = round(100 * ((current_date - start_date).total_seconds() / simulation_duration), 2)
            sys.stdout.write(&#34;\r{} %% of Simulation done!!&#34;.format(evolution_percentage))
            sys.stdout.flush()

            # Compute the time window id
            if self.dynamic:
                new_time_window_id = time_window_id + int((current_date - start_date) / self.period)
                if current_time_window_id &gt; new_time_window_id:  # if we change time window
                    # Re compute the Activity Daily Profiles
                    current_time_window_id = new_time_window_id
                    macro_ADPs = self.get_activity_daily_profiles(time_window_id=self.last_time_window_id)
            else:
                current_time_window_id = time_window_id

            # Compute the time step id

            day_date = dt.datetime.combine(pd.to_datetime(current_date).date(), dt.datetime.min.time())

            time_step_id = math.ceil((current_date - day_date).total_seconds() \
                                     / self.time_step.total_seconds()) % int(self.period / self.time_step)

            # Choose the next Activity

            set_episodes = []
            scores_episodes = []

            for set_episode, macro_activity in self.activity_objects.items():
                # # Transition probability
                # if previous_event == None:
                #     prob_score = 1
                # else:
                #     prob_score = transition_matrix.loc[str(previous_event.get_set_episode())][str(set_episode)]

                # ADP score
                ADP_value = macro_ADPs[set_episode][time_step_id]
                # ADP_score = ADP_value if rand &gt; ADP_value else 1

                # TODO : Linear function for Activity selection
                score = ADP_value

                set_episodes.append(set_episode)
                scores_episodes.append(score)

            scores_episodes = np.asarray(scores_episodes)

            scores_episodes = scores_episodes / sum(scores_episodes)

            scores_episodes = np.cumsum(scores_episodes)

            rand = random.random()

            chosen_set_episode = None
            for i in range(len(scores_episodes)):
                if rand &lt;= scores_episodes[i]:
                    chosen_set_episode = set_episodes[i]
                    break

            # # Pick the episode with the max score
            # chosen_set_episode = max(scores.items(), key=operator.itemgetter(1))[0]

            if chosen_set_episode is None:  # Nothing happens
                current_date += idle_duration
                continue

            chosen_macro_activity = self.get_macro_activity_from_name(chosen_set_episode)

            # print(&#34;Time step ID : {}&#34;.format(time_step_id))
            # print(&#34;Chosen Activity : {} &#34;.format(chosen_macro_activity))

            # Simulate the MACRO-ACTIVITY
            macro_activity_events = chosen_macro_activity.simulate(start_date=current_date, time_step_id=time_step_id,
                                                                   time_window_id=current_time_window_id)
            simulated_dataset = simulated_dataset.append(macro_activity_events)

            current_date = simulated_dataset.end_date.max().to_pydatetime()

            # previous_event = chosen_macro_activity

        sys.stdout.write(&#34;\n&#34;)

        return simulated_dataset

    def dump_data(self, output):
        &#34;&#34;&#34;
        Dump all the data related to the macro-activities
        :param output:
        :return:
        &#34;&#34;&#34;
        for set_episode, macro_activity in self.activity_objects.items():
            macro_activity.dump_data(output=output)

    def ADP_screenshot(self, time_window_id=0):
        &#34;&#34;&#34;
        Screenshot of all the macro-activities daily profiles
        :param time_window_id:
        :return:
        &#34;&#34;&#34;

        macro_ADPs = self.get_activity_daily_profiles(time_window_id=time_window_id)

        df_ADPs = pd.DataFrame.from_dict(macro_ADPs, orient=&#39;index&#39;)

        print()


def plot_markov_chain(matrix, labels, threshold=0.1):
    &#34;&#34;&#34;
    Plot the markov chain corresponding to the distance_matrix
    :param matrix:
    :param labels:
    :return:
    &#34;&#34;&#34;
    G = nx.MultiDiGraph()
    G.add_nodes_from(labels)
    print(f&#39;Nodes:\n{G.nodes()}\n&#39;)

    edges_wts = {}
    for col in matrix.columns:
        for idx in matrix.index:
            if matrix.loc[idx, col] &gt; threshold:
                edges_wts[(idx, col)] = round(matrix.loc[idx, col], 2)

    # edges represent transition probabilities
    for k, v in edges_wts.items():
        tmp_origin, tmp_destination = k[0], k[1]
        G.add_edge(tmp_origin, tmp_destination, weight=v, label=v)

    pos = nx.drawing.nx_pydot.graphviz_layout(G, prog=&#39;dot&#39;)
    nx.draw_networkx(G, pos)

    edge_labels = {(n1, n2): d[&#39;label&#39;] for n1, n2, d in G.edges(data=True)}
    nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels)

    filename = &#39;markov&#39;
    nx.drawing.nx_pydot.write_dot(G, filename + &#39;.dot&#39;)
    check_call([&#39;dot&#39;, &#39;-Tpng&#39;, filename + &#39;.dot&#39;, &#39;-o&#39;, filename + &#39;.png&#39;])

    plt.clf()
    plt.axis(&#39;off&#39;)
    img = mpimg.imread(filename + &#39;.png&#39;)
    plt.imshow(img)
    plt.title(&#39;Markov Chain between activities&#39;)
    plt.show()</code></pre>
            </details>
        </section>
        <section>
        </section>
        <section>
        </section>
        <section>
            <h2 class="section-title" id="header-functions">Functions</h2>
            <dl>
                <dt id="Simulation.ActivityManager.forecast_durations"><code class="name flex">
                    <span>def <span class="ident">forecast_durations</span></span>(<span>duration_data, train_ratio, nb_periods_to_forecast)</span>
                </code></dt>
                <dd>
                    <div class="desc"><p>forecast the activities duration
                        :param train_ratio:
                        :param last_time_window_id:
                        :param nb_periods_to_forecast:
                        :param display:
                        :return: Two dict like object {label: r2_score}</p></div>
                    <details class="source">
                        <summary>
                            <span>Expand source code</span>
                        </summary>
                        <pre><code class="python">def forecast_durations(duration_data, train_ratio, nb_periods_to_forecast):
    &#34;&#34;&#34;
    forecast the activities duration
    :param train_ratio:
    :param last_time_window_id:
    :param nb_periods_to_forecast:
    :param display:
    :return: Two dict like object {label: r2_score}
    &#34;&#34;&#34;

    duration_dist_errors = pd.DataFrame(columns=[&#39;label&#39;, &#39;mean_error&#39;, &#39;std_error&#39;])

    # Fill history count df until last time window registered

    last_time_window_id = int(duration_data.tw_id.max())

    forecast_df = pd.DataFrame(columns=[&#39;tw_id&#39;, &#39;mean&#39;, &#39;std&#39;])

    forecast_df.tw_id = np.arange(last_time_window_id, last_time_window_id + nb_periods_to_forecast)

    data = duration_data[[&#39;mean&#39;, &#39;std&#39;]]

    train_size = int(len(data) * train_ratio)

    train, test = data[:train_size], data[train_size:]

    test_size = test.shape[0]

    model = VARMAX(train.values, order=(2, 2), enforce_stationarity=True, enforce_invertibility=False)

    try:
        model = model.fit(disp=False)
    except np.linalg.LinAlgError as e:
        return None

    raw_forecast = model.forecast(test_size + nb_periods_to_forecast)

    index = np.arange(train_size + 1, train_size + 1 + test_size + nb_periods_to_forecast)
    raw_forecast = pd.DataFrame(raw_forecast, index, [&#39;mean&#39;, &#39;std&#39;])

    validation_forecast = raw_forecast[:test_size]
    # nmse_error_mean = mean_squared_error(test[&#39;mean&#39;], validation_forecast[&#39;mean&#39;]) / np.mean(test[&#39;mean&#39;])
    # nmse_error_std = mean_squared_error(test[&#39;std&#39;], validation_forecast[&#39;std&#39;]) / np.mean(test[&#39;std&#39;])

    # Forecast to use
    forecasts = raw_forecast[test_size:]

    # Replace all negative values by 0
    forecasts[forecasts &lt; 0] = 0

    return forecasts</code></pre>
                    </details>
                </dd>
                <dt id="Simulation.ActivityManager.plot_markov_chain"><code class="name flex">
                    <span>def <span
                            class="ident">plot_markov_chain</span></span>(<span>matrix, labels, threshold=0.1)</span>
                </code></dt>
                <dd>
                    <div class="desc"><p>Plot the markov chain corresponding to the distance_matrix
                        :param matrix:
                        :param labels:
                        :return:</p></div>
                    <details class="source">
                        <summary>
                            <span>Expand source code</span>
                        </summary>
                        <pre><code class="python">def plot_markov_chain(matrix, labels, threshold=0.1):
    &#34;&#34;&#34;
    Plot the markov chain corresponding to the distance_matrix
    :param matrix:
    :param labels:
    :return:
    &#34;&#34;&#34;
    G = nx.MultiDiGraph()
    G.add_nodes_from(labels)
    print(f&#39;Nodes:\n{G.nodes()}\n&#39;)

    edges_wts = {}
    for col in matrix.columns:
        for idx in matrix.index:
            if matrix.loc[idx, col] &gt; threshold:
                edges_wts[(idx, col)] = round(matrix.loc[idx, col], 2)

    # edges represent transition probabilities
    for k, v in edges_wts.items():
        tmp_origin, tmp_destination = k[0], k[1]
        G.add_edge(tmp_origin, tmp_destination, weight=v, label=v)

    pos = nx.drawing.nx_pydot.graphviz_layout(G, prog=&#39;dot&#39;)
    nx.draw_networkx(G, pos)

    edge_labels = {(n1, n2): d[&#39;label&#39;] for n1, n2, d in G.edges(data=True)}
    nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels)

    filename = &#39;markov&#39;
    nx.drawing.nx_pydot.write_dot(G, filename + &#39;.dot&#39;)
    check_call([&#39;dot&#39;, &#39;-Tpng&#39;, filename + &#39;.dot&#39;, &#39;-o&#39;, filename + &#39;.png&#39;])

    plt.clf()
    plt.axis(&#39;off&#39;)
    img = mpimg.imread(filename + &#39;.png&#39;)
    plt.imshow(img)
    plt.title(&#39;Markov Chain between activities&#39;)
    plt.show()</code></pre>
                    </details>
                </dd>
            </dl>
        </section>
        <section>
            <h2 class="section-title" id="header-classes">Classes</h2>
            <dl>
                <dt id="Simulation.ActivityManager.ActivityManager"><code class="flex name class">
                    <span>class <span class="ident">ActivityManager</span></span>
                    <span>(</span><span>name, period, time_step, tep, window_size=None, max_no_news=None, dynamic=False)</span>
                </code></dt>
                <dd>
                    <div class="desc"><p>Manage the macro-activities created in the time windows</p>
                        <p>Initialisation of the Manager
                            :param name:
                            :param period:
                            :param time_step: Time discretization parameter</p></div>
                    <details class="source">
                        <summary>
                            <span>Expand source code</span>
                        </summary>
                        <pre><code class="python">class ActivityManager:
    &#34;&#34;&#34;
    Manage the macro-activities created in the time windows
    &#34;&#34;&#34;

    # OBSOLESCENCE_DURATION_DAYS = 60

    def __init__(self, name, period, time_step, tep, window_size=None, max_no_news=None, dynamic=False, ):
        &#34;&#34;&#34;
        Initialisation of the Manager
        :param name:
        :param period:
        :param time_step: Time discretization parameter
        &#34;&#34;&#34;
        self.name = name
        self.period = period
        self.tep = tep
        self.time_step = time_step
        self.window_size = window_size
        self.OBSOLESCENCE_DURATION_DAYS = max_no_news
        self.discovered_episodes = []  # All the episodes discovered until then
        self.activity_objects = {}  # The Activity/MacroActivity objects
        self.mixed_occurrences = pd.DataFrame(columns=[&#39;date&#39;, &#39;end_date&#39;, &#39;label&#39;, &#39;tw_id&#39;])
        self.last_time_window_id = 0
        self.dynamic = dynamic
        self.nb_new_episodes = []
        self.labels_duration_dist = {}

    def update(self, episode, occurrences, events, time_window_id=0, display=False):
        &#34;&#34;&#34;
        Update the Macro-Activity Object related to the macro-activity discovered if they already exist OR create a
        new Object
        :param episode:
        :param occurrences:
        :param events:
        :param time_window_id:
        :return:
        &#34;&#34;&#34;

        set_episode = frozenset(episode)

        if set_episode not in self.discovered_episodes:  # Create a new Macro-Activity Object
            activity_object = MacroActivity(episode=episode, period=self.period, time_step=self.time_step, tep=self.tep)

            self.discovered_episodes.append(set_episode)
            self.activity_objects[set_episode] = activity_object

        activity_object = self.activity_objects[set_episode]
        activity_object.add_time_window(occurrences=occurrences, events=events,
                                        time_window_id=time_window_id, display=False)

        occurrences[&#39;label&#39;] = [str(set_episode) for _ in range(len(occurrences))]
        occurrences[&#39;tw_id&#39;] = time_window_id

        self.mixed_occurrences = pd.concat(
            [self.mixed_occurrences, occurrences[[&#39;date&#39;, &#39;end_date&#39;, &#39;label&#39;, &#39;tw_id&#39;]]]).drop_duplicates(keep=False)

        self.mixed_occurrences.sort_values([&#39;date&#39;], inplace=True)

        self.last_time_window_id = time_window_id

        if self.dynamic:
            self.obsolescence_check()

        self.nb_new_episodes.append(len(self.discovered_episodes))

    def get_macro_activity_from_name(self, set_episode):
        &#34;&#34;&#34;
        return the MacroActivity Object related to the episode
        :param set_episode:
        :return:
        &#34;&#34;&#34;

        # set_episode = frozenset(set_episode)

        return self.activity_objects[set_episode]

    def build_transition_matrix(self, time_window_id=0, display=False):
        &#34;&#34;&#34;
        Build a transition distance_matrix for all the available activities
        :return:
        &#34;&#34;&#34;

        data = self.mixed_occurrences[self.mixed_occurrences.tw_id == time_window_id].copy()
        labels = data.label.unique()

        data[&#39;next_label&#39;] = data[&#39;label&#39;].shift(-1)
        data.dropna(inplace=True)

        matrix = pd.DataFrame(columns=labels, index=labels)

        for i_label in labels:
            i_data = data[data.label == i_label]
            nb_i_occ = len(i_data)
            for j_label in labels:
                nb_j_occ = len(i_data[i_data.next_label == j_label])
                matrix.loc[i_label, j_label] = nb_j_occ / nb_i_occ

        if display:
            plot_markov_chain(matrix, labels, threshold=0.0)

        return matrix

    def obsolescence_check(self):
        &#34;&#34;&#34;
        Remove Macro-Activities which are obsoletes
        :return:
        &#34;&#34;&#34;

        obsoletes_episodes = []

        for set_episode, macro_activity_object in self.activity_objects.items():
            # Computer Macro-Activity Weight !!
            last_update_id = int(macro_activity_object.count_histogram.tw_id.max())

            nb_period_without_news = self.last_time_window_id - last_update_id

            if nb_period_without_news &gt; self.OBSOLESCENCE_DURATION_DAYS:
                obsoletes_episodes.append(set_episode)
                print(print(f&#34;{list(set_episode)} : OBSOLETE EPISODE&#34;))

        # DESTROY OBSOLETE EPISODES
        for set_episode in obsoletes_episodes:
            self.activity_objects.pop(set_episode)
            self.discovered_episodes.remove(set_episode)

    def build_forecasting_models(self, train_ratio, nb_periods_to_forecast, display=False, debug=False):
        &#34;&#34;&#34;
        Build forecasting models for Macro-Activity parameters
        :param debug:
        :param nb_periods_to_forecast:
        :param train_ratio: ratio of data used for training
        :param method: method used for the forecasting
        :param display:
        :return:
        &#34;&#34;&#34;

        ADP_error_df = pd.DataFrame(columns=[&#39;episode&#39;, &#39;rmse&#39;])
        duration_error_df = pd.DataFrame(columns=[&#39;episode&#39;, &#39;mean_rmse&#39;, &#39;std_rmse&#39;, &#39;label&#39;])

        # Build forecasting models
        i = 0

        for set_episode, macro_activity_object in self.activity_objects.items():
            print(f&#34;{list(set_episode)} : {macro_activity_object}&#34;)

            i += 1

            # ACTIVITY DAILY PROFILE FORECASTING
            # TODO : Enable ADP Forecasting

            # Fill

            ADP_error = macro_activity_object.forecast_history_count(train_ratio=train_ratio,
                                                                     last_time_window_id=self.last_time_window_id,
                                                                     nb_periods_to_forecast=nb_periods_to_forecast,
                                                                     display=debug)
            #
            # ADP_error_df.at[len(ADP_error_df)] = [tuple(set_episode), ADP_error]

            # ACTIVITIES DURATIONS FORECASTING
            # TODO : Monitor the error on forecasting models for duration
            for label in macro_activity_object.episode:
                macro_activity_object.duration_distrib[label] = self.labels_duration_dist[label]
            #
            # error_df = macro_activity_object.forecast_durations(train_ratio=train_ratio,
            #                                                     last_time_window_id=self.last_time_window_id,
            #                                                     nb_periods_to_forecast=nb_periods_to_forecast,
            #                                                     display=debug)
            #
            # for _, row in error_df.iterrows():
            #     duration_error_df.loc[len(duration_error_df)] = [tuple(set_episode), row[&#39;mean_error&#39;],
            #                                                      row[&#39;std_error&#39;], row[&#39;label&#39;]]

            # STOP HERE IF SINGLE-ACTIVITY
            # if len(set_episode) &lt; 2:
            #     break

            # EXECUTION ORDER FORECASTING
            # exec_order_error = macro_activity_object.forecast_execution_order(
            #     train_ratio=train_ratio, last_time_window_id=self.last_time_window_id,
            #     nb_periods_to_forecast=nb_periods_to_forecast, debug=debug)

            sys.stdout.write(
                &#34;\r{}/{} Macro-Activities Forecasting models done...&#34;.format(i, len(self.activity_objects)))
            sys.stdout.flush()
        sys.stdout.write(&#34;\n&#34;)

        if display:
            # Drop NAN
            ADPs_rmse = ADP_error_df.replace([np.inf, -np.inf], np.nan).dropna().rmse.values
            mean_durations_rmse = duration_error_df.replace([np.inf, -np.inf], np.nan).dropna().mean_rmse.values
            std_durations_rmse = duration_error_df.replace([np.inf, -np.inf], np.nan).dropna().std_rmse.values

            sns.kdeplot(ADPs_rmse, shade_lowest=False, shade=True, label=&#39;ADP Errors&#39;)
            plt.show()
            sns.kdeplot(mean_durations_rmse, shade_lowest=False, shade=True, label=&#39;Mean Duration Errors&#39;)
            sns.kdeplot(std_durations_rmse, shade_lowest=False, shade=True, label=&#39;STD Duration Errors&#39;)
            plt.show()

        # plt.hist(list(error_df.error.values))
        # plt.title(&#39;NMSE Distribution for all macro_activities forecasting models&#39;)
        # plt.show()

        return ADP_error_df, duration_error_df

    def build_forecasting_duration(self, dataset, train_ratio, nb_periods_to_forecast):
        &#34;&#34;&#34;
        :param train_ratio:
        :param nb_periods_to_forecast:
        :param display:
        :param debug:
        :return:
        &#34;&#34;&#34;
        time_window_duration = dt.timedelta(days=self.window_size)
        start_date = dataset.date.min().to_pydatetime()
        end_date = dataset.date.max().to_pydatetime() - time_window_duration

        dataset[&#39;duration&#39;] = dataset.end_date - dataset.date
        dataset[&#39;duration&#39;] = dataset[&#39;duration&#39;].apply(lambda x: x.total_seconds())

        labels = dataset.label.unique()

        labels_duration_dist = {}
        for label in labels:
            df = pd.DataFrame(columns=[&#39;tw_id&#39;, &#39;mean&#39;, &#39;std&#39;])
            labels_duration_dist[label] = df

        nb_tw = math.floor((end_date - start_date) / self.period)

        for tw_id in range(nb_tw):
            tw_start_date = start_date + dt.timedelta(days=tw_id)
            tw_end_date = tw_start_date + dt.timedelta(days=self.window_size)

            tw_dataset = dataset[(dataset.date &gt;= tw_start_date) &amp; (dataset.date &lt; tw_end_date)]

            for label in labels:
                mean_duration = np.mean(tw_dataset[tw_dataset.label == label][&#39;duration&#39;])
                std_duration = np.std(tw_dataset[tw_dataset.label == label][&#39;duration&#39;])

                df = labels_duration_dist[label]
                df.loc[tw_id] = [tw_id, mean_duration, std_duration]

        for label in labels:
            label_data = labels_duration_dist[label]

            forecast_data = forecast_durations(label_data, train_ratio, nb_periods_to_forecast)

            if forecast_data is None:
                forecast_data = pd.DataFrame(columns=[&#39;tw_id&#39;, &#39;mean&#39;, &#39;std&#39;])
                forecast_data[&#39;tw_id&#39;] = np.arange(len(label_data), len(label_data) + nb_periods_to_forecast)
                forecast_data[&#39;mean&#39;] = [label_data[&#39;mean&#39;].values[-1]] * nb_periods_to_forecast
                forecast_data[&#39;std&#39;] = [label_data[&#39;std&#39;].values[-1]] * nb_periods_to_forecast
                label_data = label_data.append(forecast_data, ignore_index=True)
            else:
                forecast_data[&#39;tw_id&#39;] = np.arange(len(label_data), len(label_data) + nb_periods_to_forecast)
                label_data = label_data.append(forecast_data, ignore_index=True)

            label_data.fillna(0, inplace=True)

        self.labels_duration_dist = labels_duration_dist

    def get_activity_daily_profiles(self, time_window_id=0):
        &#34;&#34;&#34;
        :param time_window_id:
        :return: a dict-like object of Macro-activities ADP
        &#34;&#34;&#34;

        macro_ADPs = {}

        activities_count_histogram = pd.DataFrame()

        for set_episode, macro_activity in self.activity_objects.items():
            count_histogram = macro_activity.get_count_histogram(time_window_id=time_window_id)
            count_histogram.drop([&#39;tw_id&#39;], axis=1, inplace=True)
            count_histogram.index = [set_episode]
            activities_count_histogram = activities_count_histogram.append(count_histogram)

        # No &#39;idle&#39; times
        # activities_count_histogram = activities_count_histogram.div(activities_count_histogram.sum(axis=0), axis=1)

        # With &#39;idle&#39; times

        div_array = activities_count_histogram.sum(axis=0)

        div_array = np.where(div_array &gt; self.window_size, div_array, self.window_size)

        activities_occ_probability = activities_count_histogram.div(div_array, axis=1)

        activities_occ_probability.fillna(0, inplace=True)

        for index, row in activities_occ_probability.iterrows():
            macro_ADPs[index] = row.values

        return macro_ADPs

    def simulate(self, start_date, end_date, idle_duration, time_window_id=0):
        &#34;&#34;&#34;
        Generate data between two dates using the model parameters for the selected time_window_id
        :param start_date: Start date of the simulation
        :param end_date: end date
        :param idle_duration: duration of a idle period of time
        :param time_window_id: selected time window id
        :return:
        &#34;&#34;&#34;

        simulated_dataset = pd.DataFrame(columns=[&#39;date&#39;, &#39;end_date&#39;, &#39;label&#39;])

        # Use
        previous_event = None
        current_date = start_date

        simulation_duration = (end_date - start_date).total_seconds()

        macro_ADPs = self.get_activity_daily_profiles(time_window_id=time_window_id)

        # transition_matrix = self.build_transition_matrix(time_window_id=time_window_id)

        current_time_window_id = time_window_id

        while current_date &lt; end_date:

            evolution_percentage = round(100 * ((current_date - start_date).total_seconds() / simulation_duration), 2)
            sys.stdout.write(&#34;\r{} %% of Simulation done!!&#34;.format(evolution_percentage))
            sys.stdout.flush()

            # Compute the time window id
            if self.dynamic:
                new_time_window_id = time_window_id + int((current_date - start_date) / self.period)
                if current_time_window_id &gt; new_time_window_id:  # if we change time window
                    # Re compute the Activity Daily Profiles
                    current_time_window_id = new_time_window_id
                    macro_ADPs = self.get_activity_daily_profiles(time_window_id=self.last_time_window_id)
            else:
                current_time_window_id = time_window_id

            # Compute the time step id

            day_date = dt.datetime.combine(pd.to_datetime(current_date).date(), dt.datetime.min.time())

            time_step_id = math.ceil((current_date - day_date).total_seconds() \
                                     / self.time_step.total_seconds()) % int(self.period / self.time_step)

            # Choose the next Activity

            set_episodes = []
            scores_episodes = []

            for set_episode, macro_activity in self.activity_objects.items():
                # # Transition probability
                # if previous_event == None:
                #     prob_score = 1
                # else:
                #     prob_score = transition_matrix.loc[str(previous_event.get_set_episode())][str(set_episode)]

                # ADP score
                ADP_value = macro_ADPs[set_episode][time_step_id]
                # ADP_score = ADP_value if rand &gt; ADP_value else 1

                # TODO : Linear function for Activity selection
                score = ADP_value

                set_episodes.append(set_episode)
                scores_episodes.append(score)

            scores_episodes = np.asarray(scores_episodes)

            scores_episodes = scores_episodes / sum(scores_episodes)

            scores_episodes = np.cumsum(scores_episodes)

            rand = random.random()

            chosen_set_episode = None
            for i in range(len(scores_episodes)):
                if rand &lt;= scores_episodes[i]:
                    chosen_set_episode = set_episodes[i]
                    break

            # # Pick the episode with the max score
            # chosen_set_episode = max(scores.items(), key=operator.itemgetter(1))[0]

            if chosen_set_episode is None:  # Nothing happens
                current_date += idle_duration
                continue

            chosen_macro_activity = self.get_macro_activity_from_name(chosen_set_episode)

            # print(&#34;Time step ID : {}&#34;.format(time_step_id))
            # print(&#34;Chosen Activity : {} &#34;.format(chosen_macro_activity))

            # Simulate the MACRO-ACTIVITY
            macro_activity_events = chosen_macro_activity.simulate(start_date=current_date, time_step_id=time_step_id,
                                                                   time_window_id=current_time_window_id)
            simulated_dataset = simulated_dataset.append(macro_activity_events)

            current_date = simulated_dataset.end_date.max().to_pydatetime()

            # previous_event = chosen_macro_activity

        sys.stdout.write(&#34;\n&#34;)

        return simulated_dataset

    def dump_data(self, output):
        &#34;&#34;&#34;
        Dump all the data related to the macro-activities
        :param output:
        :return:
        &#34;&#34;&#34;
        for set_episode, macro_activity in self.activity_objects.items():
            macro_activity.dump_data(output=output)

    def ADP_screenshot(self, time_window_id=0):
        &#34;&#34;&#34;
        Screenshot of all the macro-activities daily profiles
        :param time_window_id:
        :return:
        &#34;&#34;&#34;

        macro_ADPs = self.get_activity_daily_profiles(time_window_id=time_window_id)

        df_ADPs = pd.DataFrame.from_dict(macro_ADPs, orient=&#39;index&#39;)

        print()</code></pre>
                    </details>
                    <h3>Methods</h3>
                    <dl>
                        <dt id="Simulation.ActivityManager.ActivityManager.ADP_screenshot"><code class="name flex">
                            <span>def <span
                                    class="ident">ADP_screenshot</span></span>(<span>self, time_window_id=0)</span>
                        </code></dt>
                        <dd>
                            <div class="desc"><p>Screenshot of all the macro-activities daily profiles
                                :param time_window_id:
                                :return:</p></div>
                            <details class="source">
                                <summary>
                                    <span>Expand source code</span>
                                </summary>
                                <pre><code class="python">def ADP_screenshot(self, time_window_id=0):
    &#34;&#34;&#34;
    Screenshot of all the macro-activities daily profiles
    :param time_window_id:
    :return:
    &#34;&#34;&#34;

    macro_ADPs = self.get_activity_daily_profiles(time_window_id=time_window_id)

    df_ADPs = pd.DataFrame.from_dict(macro_ADPs, orient=&#39;index&#39;)

    print()</code></pre>
                            </details>
                        </dd>
                        <dt id="Simulation.ActivityManager.ActivityManager.build_forecasting_duration"><code
                                class="name flex">
                            <span>def <span class="ident">build_forecasting_duration</span></span>(<span>self, dataset, train_ratio, nb_periods_to_forecast)</span>
                        </code></dt>
                        <dd>
                            <div class="desc"><p>:param train_ratio:
                                :param nb_periods_to_forecast:
                                :param display:
                                :param debug:
                                :return:</p></div>
                            <details class="source">
                                <summary>
                                    <span>Expand source code</span>
                                </summary>
                                <pre><code class="python">def build_forecasting_duration(self, dataset, train_ratio, nb_periods_to_forecast):
    &#34;&#34;&#34;
    :param train_ratio:
    :param nb_periods_to_forecast:
    :param display:
    :param debug:
    :return:
    &#34;&#34;&#34;
    time_window_duration = dt.timedelta(days=self.window_size)
    start_date = dataset.date.min().to_pydatetime()
    end_date = dataset.date.max().to_pydatetime() - time_window_duration

    dataset[&#39;duration&#39;] = dataset.end_date - dataset.date
    dataset[&#39;duration&#39;] = dataset[&#39;duration&#39;].apply(lambda x: x.total_seconds())

    labels = dataset.label.unique()

    labels_duration_dist = {}
    for label in labels:
        df = pd.DataFrame(columns=[&#39;tw_id&#39;, &#39;mean&#39;, &#39;std&#39;])
        labels_duration_dist[label] = df

    nb_tw = math.floor((end_date - start_date) / self.period)

    for tw_id in range(nb_tw):
        tw_start_date = start_date + dt.timedelta(days=tw_id)
        tw_end_date = tw_start_date + dt.timedelta(days=self.window_size)

        tw_dataset = dataset[(dataset.date &gt;= tw_start_date) &amp; (dataset.date &lt; tw_end_date)]

        for label in labels:
            mean_duration = np.mean(tw_dataset[tw_dataset.label == label][&#39;duration&#39;])
            std_duration = np.std(tw_dataset[tw_dataset.label == label][&#39;duration&#39;])

            df = labels_duration_dist[label]
            df.loc[tw_id] = [tw_id, mean_duration, std_duration]

    for label in labels:
        label_data = labels_duration_dist[label]

        forecast_data = forecast_durations(label_data, train_ratio, nb_periods_to_forecast)

        if forecast_data is None:
            forecast_data = pd.DataFrame(columns=[&#39;tw_id&#39;, &#39;mean&#39;, &#39;std&#39;])
            forecast_data[&#39;tw_id&#39;] = np.arange(len(label_data), len(label_data) + nb_periods_to_forecast)
            forecast_data[&#39;mean&#39;] = [label_data[&#39;mean&#39;].values[-1]] * nb_periods_to_forecast
            forecast_data[&#39;std&#39;] = [label_data[&#39;std&#39;].values[-1]] * nb_periods_to_forecast
            label_data = label_data.append(forecast_data, ignore_index=True)
        else:
            forecast_data[&#39;tw_id&#39;] = np.arange(len(label_data), len(label_data) + nb_periods_to_forecast)
            label_data = label_data.append(forecast_data, ignore_index=True)

        label_data.fillna(0, inplace=True)

    self.labels_duration_dist = labels_duration_dist</code></pre>
                            </details>
                        </dd>
                        <dt id="Simulation.ActivityManager.ActivityManager.build_forecasting_models"><code
                                class="name flex">
                            <span>def <span class="ident">build_forecasting_models</span></span>(<span>self, train_ratio, nb_periods_to_forecast, display=False, debug=False)</span>
                        </code></dt>
                        <dd>
                            <div class="desc"><p>Build forecasting models for Macro-Activity parameters
                                :param debug:
                                :param nb_periods_to_forecast:
                                :param train_ratio: ratio of data used for training
                                :param method: method used for the forecasting
                                :param display:
                                :return:</p></div>
                            <details class="source">
                                <summary>
                                    <span>Expand source code</span>
                                </summary>
                                <pre><code class="python">def build_forecasting_models(self, train_ratio, nb_periods_to_forecast, display=False, debug=False):
    &#34;&#34;&#34;
    Build forecasting models for Macro-Activity parameters
    :param debug:
    :param nb_periods_to_forecast:
    :param train_ratio: ratio of data used for training
    :param method: method used for the forecasting
    :param display:
    :return:
    &#34;&#34;&#34;

    ADP_error_df = pd.DataFrame(columns=[&#39;episode&#39;, &#39;rmse&#39;])
    duration_error_df = pd.DataFrame(columns=[&#39;episode&#39;, &#39;mean_rmse&#39;, &#39;std_rmse&#39;, &#39;label&#39;])

    # Build forecasting models
    i = 0

    for set_episode, macro_activity_object in self.activity_objects.items():
        print(f&#34;{list(set_episode)} : {macro_activity_object}&#34;)

        i += 1

        # ACTIVITY DAILY PROFILE FORECASTING
        # TODO : Enable ADP Forecasting

        # Fill

        ADP_error = macro_activity_object.forecast_history_count(train_ratio=train_ratio,
                                                                 last_time_window_id=self.last_time_window_id,
                                                                 nb_periods_to_forecast=nb_periods_to_forecast,
                                                                 display=debug)
        #
        # ADP_error_df.at[len(ADP_error_df)] = [tuple(set_episode), ADP_error]

        # ACTIVITIES DURATIONS FORECASTING
        # TODO : Monitor the error on forecasting models for duration
        for label in macro_activity_object.episode:
            macro_activity_object.duration_distrib[label] = self.labels_duration_dist[label]
        #
        # error_df = macro_activity_object.forecast_durations(train_ratio=train_ratio,
        #                                                     last_time_window_id=self.last_time_window_id,
        #                                                     nb_periods_to_forecast=nb_periods_to_forecast,
        #                                                     display=debug)
        #
        # for _, row in error_df.iterrows():
        #     duration_error_df.loc[len(duration_error_df)] = [tuple(set_episode), row[&#39;mean_error&#39;],
        #                                                      row[&#39;std_error&#39;], row[&#39;label&#39;]]

        # STOP HERE IF SINGLE-ACTIVITY
        # if len(set_episode) &lt; 2:
        #     break

        # EXECUTION ORDER FORECASTING
        # exec_order_error = macro_activity_object.forecast_execution_order(
        #     train_ratio=train_ratio, last_time_window_id=self.last_time_window_id,
        #     nb_periods_to_forecast=nb_periods_to_forecast, debug=debug)

        sys.stdout.write(
            &#34;\r{}/{} Macro-Activities Forecasting models done...&#34;.format(i, len(self.activity_objects)))
        sys.stdout.flush()
    sys.stdout.write(&#34;\n&#34;)

    if display:
        # Drop NAN
        ADPs_rmse = ADP_error_df.replace([np.inf, -np.inf], np.nan).dropna().rmse.values
        mean_durations_rmse = duration_error_df.replace([np.inf, -np.inf], np.nan).dropna().mean_rmse.values
        std_durations_rmse = duration_error_df.replace([np.inf, -np.inf], np.nan).dropna().std_rmse.values

        sns.kdeplot(ADPs_rmse, shade_lowest=False, shade=True, label=&#39;ADP Errors&#39;)
        plt.show()
        sns.kdeplot(mean_durations_rmse, shade_lowest=False, shade=True, label=&#39;Mean Duration Errors&#39;)
        sns.kdeplot(std_durations_rmse, shade_lowest=False, shade=True, label=&#39;STD Duration Errors&#39;)
        plt.show()

    # plt.hist(list(error_df.error.values))
    # plt.title(&#39;NMSE Distribution for all macro_activities forecasting models&#39;)
    # plt.show()

    return ADP_error_df, duration_error_df</code></pre>
                            </details>
                        </dd>
                        <dt id="Simulation.ActivityManager.ActivityManager.build_transition_matrix"><code
                                class="name flex">
                            <span>def <span class="ident">build_transition_matrix</span></span>(<span>self, time_window_id=0, display=False)</span>
                        </code></dt>
                        <dd>
                            <div class="desc"><p>Build a transition distance_matrix for all the available activities
                                :return:</p></div>
                            <details class="source">
                                <summary>
                                    <span>Expand source code</span>
                                </summary>
                                <pre><code class="python">def build_transition_matrix(self, time_window_id=0, display=False):
    &#34;&#34;&#34;
    Build a transition distance_matrix for all the available activities
    :return:
    &#34;&#34;&#34;

    data = self.mixed_occurrences[self.mixed_occurrences.tw_id == time_window_id].copy()
    labels = data.label.unique()

    data[&#39;next_label&#39;] = data[&#39;label&#39;].shift(-1)
    data.dropna(inplace=True)

    matrix = pd.DataFrame(columns=labels, index=labels)

    for i_label in labels:
        i_data = data[data.label == i_label]
        nb_i_occ = len(i_data)
        for j_label in labels:
            nb_j_occ = len(i_data[i_data.next_label == j_label])
            matrix.loc[i_label, j_label] = nb_j_occ / nb_i_occ

    if display:
        plot_markov_chain(matrix, labels, threshold=0.0)

    return matrix</code></pre>
                            </details>
                        </dd>
                        <dt id="Simulation.ActivityManager.ActivityManager.dump_data"><code class="name flex">
                            <span>def <span class="ident">dump_data</span></span>(<span>self, output)</span>
                        </code></dt>
                        <dd>
                            <div class="desc"><p>Dump all the data related to the macro-activities
                                :param output:
                                :return:</p></div>
                            <details class="source">
                                <summary>
                                    <span>Expand source code</span>
                                </summary>
                                <pre><code class="python">def dump_data(self, output):
    &#34;&#34;&#34;
    Dump all the data related to the macro-activities
    :param output:
    :return:
    &#34;&#34;&#34;
    for set_episode, macro_activity in self.activity_objects.items():
        macro_activity.dump_data(output=output)</code></pre>
                            </details>
                        </dd>
                        <dt id="Simulation.ActivityManager.ActivityManager.get_activity_daily_profiles"><code
                                class="name flex">
                            <span>def <span class="ident">get_activity_daily_profiles</span></span>(<span>self, time_window_id=0)</span>
                        </code></dt>
                        <dd>
                            <div class="desc"><p>:param time_window_id:
                                :return: a dict-like object of Macro-activities ADP</p></div>
                            <details class="source">
                                <summary>
                                    <span>Expand source code</span>
                                </summary>
                                <pre><code class="python">def get_activity_daily_profiles(self, time_window_id=0):
    &#34;&#34;&#34;
    :param time_window_id:
    :return: a dict-like object of Macro-activities ADP
    &#34;&#34;&#34;

    macro_ADPs = {}

    activities_count_histogram = pd.DataFrame()

    for set_episode, macro_activity in self.activity_objects.items():
        count_histogram = macro_activity.get_count_histogram(time_window_id=time_window_id)
        count_histogram.drop([&#39;tw_id&#39;], axis=1, inplace=True)
        count_histogram.index = [set_episode]
        activities_count_histogram = activities_count_histogram.append(count_histogram)

    # No &#39;idle&#39; times
    # activities_count_histogram = activities_count_histogram.div(activities_count_histogram.sum(axis=0), axis=1)

    # With &#39;idle&#39; times

    div_array = activities_count_histogram.sum(axis=0)

    div_array = np.where(div_array &gt; self.window_size, div_array, self.window_size)

    activities_occ_probability = activities_count_histogram.div(div_array, axis=1)

    activities_occ_probability.fillna(0, inplace=True)

    for index, row in activities_occ_probability.iterrows():
        macro_ADPs[index] = row.values

    return macro_ADPs</code></pre>
                            </details>
                        </dd>
                        <dt id="Simulation.ActivityManager.ActivityManager.get_macro_activity_from_name"><code
                                class="name flex">
                            <span>def <span class="ident">get_macro_activity_from_name</span></span>(<span>self, set_episode)</span>
                        </code></dt>
                        <dd>
                            <div class="desc"><p>return the MacroActivity Object related to the episode
                                :param set_episode:
                                :return:</p></div>
                            <details class="source">
                                <summary>
                                    <span>Expand source code</span>
                                </summary>
                                <pre><code class="python">def get_macro_activity_from_name(self, set_episode):
    &#34;&#34;&#34;
    return the MacroActivity Object related to the episode
    :param set_episode:
    :return:
    &#34;&#34;&#34;

    # set_episode = frozenset(set_episode)

    return self.activity_objects[set_episode]</code></pre>
                            </details>
                        </dd>
                        <dt id="Simulation.ActivityManager.ActivityManager.obsolescence_check"><code class="name flex">
                            <span>def <span class="ident">obsolescence_check</span></span>(<span>self)</span>
                        </code></dt>
                        <dd>
                            <div class="desc"><p>Remove Macro-Activities which are obsoletes
                                :return:</p></div>
                            <details class="source">
                                <summary>
                                    <span>Expand source code</span>
                                </summary>
                                <pre><code class="python">def obsolescence_check(self):
    &#34;&#34;&#34;
    Remove Macro-Activities which are obsoletes
    :return:
    &#34;&#34;&#34;

    obsoletes_episodes = []

    for set_episode, macro_activity_object in self.activity_objects.items():
        # Computer Macro-Activity Weight !!
        last_update_id = int(macro_activity_object.count_histogram.tw_id.max())

        nb_period_without_news = self.last_time_window_id - last_update_id

        if nb_period_without_news &gt; self.OBSOLESCENCE_DURATION_DAYS:
            obsoletes_episodes.append(set_episode)
            print(print(f&#34;{list(set_episode)} : OBSOLETE EPISODE&#34;))

    # DESTROY OBSOLETE EPISODES
    for set_episode in obsoletes_episodes:
        self.activity_objects.pop(set_episode)
        self.discovered_episodes.remove(set_episode)</code></pre>
                            </details>
                        </dd>
                        <dt id="Simulation.ActivityManager.ActivityManager.simulate"><code class="name flex">
                            <span>def <span class="ident">simulate</span></span>(<span>self, start_date, end_date, idle_duration, time_window_id=0)</span>
                        </code></dt>
                        <dd>
                            <div class="desc"><p>Generate data between two dates using the model parameters for the
                                selected time_window_id
                                :param start_date: Start date of the simulation
                                :param end_date: end date
                                :param idle_duration: duration of a idle period of time
                                :param time_window_id: selected time window id
                                :return:</p></div>
                            <details class="source">
                                <summary>
                                    <span>Expand source code</span>
                                </summary>
                                <pre><code class="python">def simulate(self, start_date, end_date, idle_duration, time_window_id=0):
    &#34;&#34;&#34;
    Generate data between two dates using the model parameters for the selected time_window_id
    :param start_date: Start date of the simulation
    :param end_date: end date
    :param idle_duration: duration of a idle period of time
    :param time_window_id: selected time window id
    :return:
    &#34;&#34;&#34;

    simulated_dataset = pd.DataFrame(columns=[&#39;date&#39;, &#39;end_date&#39;, &#39;label&#39;])

    # Use
    previous_event = None
    current_date = start_date

    simulation_duration = (end_date - start_date).total_seconds()

    macro_ADPs = self.get_activity_daily_profiles(time_window_id=time_window_id)

    # transition_matrix = self.build_transition_matrix(time_window_id=time_window_id)

    current_time_window_id = time_window_id

    while current_date &lt; end_date:

        evolution_percentage = round(100 * ((current_date - start_date).total_seconds() / simulation_duration), 2)
        sys.stdout.write(&#34;\r{} %% of Simulation done!!&#34;.format(evolution_percentage))
        sys.stdout.flush()

        # Compute the time window id
        if self.dynamic:
            new_time_window_id = time_window_id + int((current_date - start_date) / self.period)
            if current_time_window_id &gt; new_time_window_id:  # if we change time window
                # Re compute the Activity Daily Profiles
                current_time_window_id = new_time_window_id
                macro_ADPs = self.get_activity_daily_profiles(time_window_id=self.last_time_window_id)
        else:
            current_time_window_id = time_window_id

        # Compute the time step id

        day_date = dt.datetime.combine(pd.to_datetime(current_date).date(), dt.datetime.min.time())

        time_step_id = math.ceil((current_date - day_date).total_seconds() \
                                 / self.time_step.total_seconds()) % int(self.period / self.time_step)

        # Choose the next Activity

        set_episodes = []
        scores_episodes = []

        for set_episode, macro_activity in self.activity_objects.items():
            # # Transition probability
            # if previous_event == None:
            #     prob_score = 1
            # else:
            #     prob_score = transition_matrix.loc[str(previous_event.get_set_episode())][str(set_episode)]

            # ADP score
            ADP_value = macro_ADPs[set_episode][time_step_id]
            # ADP_score = ADP_value if rand &gt; ADP_value else 1

            # TODO : Linear function for Activity selection
            score = ADP_value

            set_episodes.append(set_episode)
            scores_episodes.append(score)

        scores_episodes = np.asarray(scores_episodes)

        scores_episodes = scores_episodes / sum(scores_episodes)

        scores_episodes = np.cumsum(scores_episodes)

        rand = random.random()

        chosen_set_episode = None
        for i in range(len(scores_episodes)):
            if rand &lt;= scores_episodes[i]:
                chosen_set_episode = set_episodes[i]
                break

        # # Pick the episode with the max score
        # chosen_set_episode = max(scores.items(), key=operator.itemgetter(1))[0]

        if chosen_set_episode is None:  # Nothing happens
            current_date += idle_duration
            continue

        chosen_macro_activity = self.get_macro_activity_from_name(chosen_set_episode)

        # print(&#34;Time step ID : {}&#34;.format(time_step_id))
        # print(&#34;Chosen Activity : {} &#34;.format(chosen_macro_activity))

        # Simulate the MACRO-ACTIVITY
        macro_activity_events = chosen_macro_activity.simulate(start_date=current_date, time_step_id=time_step_id,
                                                               time_window_id=current_time_window_id)
        simulated_dataset = simulated_dataset.append(macro_activity_events)

        current_date = simulated_dataset.end_date.max().to_pydatetime()

        # previous_event = chosen_macro_activity

    sys.stdout.write(&#34;\n&#34;)

    return simulated_dataset</code></pre>
                            </details>
                        </dd>
                        <dt id="Simulation.ActivityManager.ActivityManager.update"><code class="name flex">
                            <span>def <span class="ident">update</span></span>(<span>self, episode, occurrences, events, time_window_id=0, display=False)</span>
                        </code></dt>
                        <dd>
                            <div class="desc"><p>Update the Macro-Activity Object related to the macro-activity
                                discovered if they already exist OR create a
                                new Object
                                :param episode:
                                :param occurrences:
                                :param events:
                                :param time_window_id:
                                :return:</p></div>
                            <details class="source">
                                <summary>
                                    <span>Expand source code</span>
                                </summary>
                                <pre><code class="python">def update(self, episode, occurrences, events, time_window_id=0, display=False):
    &#34;&#34;&#34;
    Update the Macro-Activity Object related to the macro-activity discovered if they already exist OR create a
    new Object
    :param episode:
    :param occurrences:
    :param events:
    :param time_window_id:
    :return:
    &#34;&#34;&#34;

    set_episode = frozenset(episode)

    if set_episode not in self.discovered_episodes:  # Create a new Macro-Activity Object
        activity_object = MacroActivity(episode=episode, period=self.period, time_step=self.time_step, tep=self.tep)

        self.discovered_episodes.append(set_episode)
        self.activity_objects[set_episode] = activity_object

    activity_object = self.activity_objects[set_episode]
    activity_object.add_time_window(occurrences=occurrences, events=events,
                                    time_window_id=time_window_id, display=False)

    occurrences[&#39;label&#39;] = [str(set_episode) for _ in range(len(occurrences))]
    occurrences[&#39;tw_id&#39;] = time_window_id

    self.mixed_occurrences = pd.concat(
        [self.mixed_occurrences, occurrences[[&#39;date&#39;, &#39;end_date&#39;, &#39;label&#39;, &#39;tw_id&#39;]]]).drop_duplicates(keep=False)

    self.mixed_occurrences.sort_values([&#39;date&#39;], inplace=True)

    self.last_time_window_id = time_window_id

    if self.dynamic:
        self.obsolescence_check()

    self.nb_new_episodes.append(len(self.discovered_episodes))</code></pre>
                            </details>
                        </dd>
                    </dl>
                </dd>
            </dl>
        </section>
    </article>
    <nav id="sidebar">
        <h1>Index</h1>
        <div class="toc">
            <ul></ul>
        </div>
        <ul id="index">
            <li><h3>Super-module</h3>
                <ul>
                    <li><code><a href="index.html" title="Simulation">Simulation</a></code></li>
                </ul>
            </li>
            <li><h3><a href="#header-functions">Functions</a></h3>
                <ul class="">
                    <li><code><a href="#Simulation.ActivityManager.forecast_durations"
                                 title="Simulation.ActivityManager.forecast_durations">forecast_durations</a></code>
                    </li>
                    <li><code><a href="#Simulation.ActivityManager.plot_markov_chain"
                                 title="Simulation.ActivityManager.plot_markov_chain">plot_markov_chain</a></code></li>
                </ul>
            </li>
            <li><h3><a href="#header-classes">Classes</a></h3>
                <ul>
                    <li>
                        <h4><code><a href="#Simulation.ActivityManager.ActivityManager"
                                     title="Simulation.ActivityManager.ActivityManager">ActivityManager</a></code></h4>
                        <ul class="">
                            <li><code><a href="#Simulation.ActivityManager.ActivityManager.ADP_screenshot"
                                         title="Simulation.ActivityManager.ActivityManager.ADP_screenshot">ADP_screenshot</a></code>
                            </li>
                            <li><code><a href="#Simulation.ActivityManager.ActivityManager.build_forecasting_duration"
                                         title="Simulation.ActivityManager.ActivityManager.build_forecasting_duration">build_forecasting_duration</a></code>
                            </li>
                            <li><code><a href="#Simulation.ActivityManager.ActivityManager.build_forecasting_models"
                                         title="Simulation.ActivityManager.ActivityManager.build_forecasting_models">build_forecasting_models</a></code>
                            </li>
                            <li><code><a href="#Simulation.ActivityManager.ActivityManager.build_transition_matrix"
                                         title="Simulation.ActivityManager.ActivityManager.build_transition_matrix">build_transition_matrix</a></code>
                            </li>
                            <li><code><a href="#Simulation.ActivityManager.ActivityManager.dump_data"
                                         title="Simulation.ActivityManager.ActivityManager.dump_data">dump_data</a></code>
                            </li>
                            <li><code><a href="#Simulation.ActivityManager.ActivityManager.get_activity_daily_profiles"
                                         title="Simulation.ActivityManager.ActivityManager.get_activity_daily_profiles">get_activity_daily_profiles</a></code>
                            </li>
                            <li><code><a href="#Simulation.ActivityManager.ActivityManager.get_macro_activity_from_name"
                                         title="Simulation.ActivityManager.ActivityManager.get_macro_activity_from_name">get_macro_activity_from_name</a></code>
                            </li>
                            <li><code><a href="#Simulation.ActivityManager.ActivityManager.obsolescence_check"
                                         title="Simulation.ActivityManager.ActivityManager.obsolescence_check">obsolescence_check</a></code>
                            </li>
                            <li><code><a href="#Simulation.ActivityManager.ActivityManager.simulate"
                                         title="Simulation.ActivityManager.ActivityManager.simulate">simulate</a></code>
                            </li>
                            <li><code><a href="#Simulation.ActivityManager.ActivityManager.update"
                                         title="Simulation.ActivityManager.ActivityManager.update">update</a></code>
                            </li>
                        </ul>
                    </li>
                </ul>
            </li>
        </ul>
    </nav>
</main>
<footer id="footer">
    <p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>