<!doctype html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta content="width=device-width, initial-scale=1, minimum-scale=1" name="viewport"/>
    <meta content="pdoc 0.9.2" name="generator"/>
    <title>Graph_Model.Build_Graph API documentation</title>
    <meta content="" name="description"/>
    <link as="style" crossorigin href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css"
          integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" rel="preload stylesheet">
    <link as="style" crossorigin
          href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css"
          integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" rel="preload stylesheet">
    <link as="style" crossorigin href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css"
          rel="stylesheet preload">
    <style>
        :root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}
    </style>
    <style media="screen and (min-width: 700px)">
        @media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}
    </style>
    <style media="print">
        @media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}
    </style>
    <script crossorigin defer integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8="
            src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js"></script>
    <script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
    <article id="content">
        <header>
            <h1 class="title">Module <code>Graph_Model.Build_Graph</code></h1>
        </header>
        <section id="section-intro">
            <details class="source">
                <summary>
                    <span>Expand source code</span>
                </summary>
                <pre><code class="python">import os
import sys

import scipy.stats as st

from Graph_Model import Acyclic_Graph

sys.path.append(os.path.join(os.path.dirname(__file__)))

from Pattern_Mining.Candidate_Study import *
from Pattern_Mining.Pattern_Discovery import *


def main():
    dataset_name = &#39;aruba&#39;

    dataset = pick_dataset(dataset_name, nb_days=120)

    output = &#34;../output/{}/ID_0&#34;.format(dataset_name)
    patterns = pickle.load(open(output + &#39;/patterns.pickle&#39;, &#39;rb&#39;))

    # Drop duplicates episodes
    patterns.drop_duplicates(subset=[&#39;Episode&#39;], keep=&#39;first&#39;, inplace=True)

    # patterns = patterns[:2]

    start_date = dataset.date.min().to_pydatetime()
    end_date = dataset.date.max().to_pydatetime()

    simulation_result = pd.DataFrame(columns=[&#39;date&#39;, &#39;end_date&#39;, &#39;label&#39;])
    all_graphs = []

    # Add graphs coming from patterns
    for _, pattern in patterns.iterrows():
        labels = list(pattern[&#39;Episode&#39;])
        period = pattern[&#39;Period&#39;]
        description = pattern[&#39;Description&#39;]
        output_folder = output + &#34;/Patterns_Graph/&#34; + &#34;_&#34;.join(labels) + &#34;/&#34;

        if not os.path.exists(os.path.dirname(output_folder)):
            try:
                os.makedirs(os.path.dirname(output_folder))
            except OSError as exc:  # Guard against race condition
                if exc.errno != errno.EEXIST:
                    raise

        start_time = t.process_time()  # To compute time spent building the graph

        pattern_graph = build_graph(data=dataset, labels=labels, period=period,
                                    start_date=start_date, end_date=end_date, output_directory=output_folder,
                                    display_graph=True)
        elapsed_time = dt.timedelta(seconds=round(t.process_time() - start_time, 1))

        print(&#34;\n&#34;)
        print(&#34;###############################&#34;)
        print(&#34;Patterns turned into graphs. Elapsed time : {}&#34;.format(elapsed_time))
        print(&#34;##############################&#34;)
        print(&#34;\n&#34;)

        all_graphs.append(pattern_graph)

    # Add graphs coming from unusual events

    data_left = pickle.load(open(output + &#39;/data_left.pickle&#39;, &#39;rb&#39;))

    activities = data_left.label.unique()


def build_graph(data, labels, period, start_date, end_date, Tep=30,
                output_directory=&#39;./&#39;, display_graph=False):
    &#39;&#39;&#39;
    Turn a pattern to a graph
    :param data: Input log_dataset
    :param labels: list of labels included in the pattern
    :param time_description: time description of the pattern {mu1 : sigma1, mu2 : sigma2, ...}
    :param tolerance_ratio: tolerance ratio to get the expected occurrences
    :param period : Periodicity of the time description
    :param start_date :
    :param end_date :
    :param Tep : [in Minutes] Maximal time interval between events in an episode occurrence. Should correspond to the maximal duration of the ADLs.
    :param output_directory Output Directory to save graphs images
    :return: A transition probability distance_matrix and a transition waiting time distance_matrix for each component of the description
    &#39;&#39;&#39;

    data = data.loc[(data.date &gt;= start_date) &amp; (data.date &lt;= end_date)].copy()

    # Find pattern occurrences
    occurrences = find_occurrences(data, tuple(labels), Tep)
    occurrences = occurrences.loc[(occurrences.date &gt;= start_date) &amp; (occurrences.date &lt;= end_date)].copy()

    # Compute relative dates
    # occurrences.loc[:, &#34;relative_date&#34;] = occurrences.date.apply(
    #     lambda x: modulo_datetime(x.to_pydatetime(), period))

    # # Drop unexpected occurrences
    # occurrences[&#34;expected&#34;] = occurrences[&#34;relative_date&#34;].apply(
    #     lambda x: is_occurence_expected(x, {mu_time: sigma_time}, period, tolerance_ratio))
    # occurrences.dropna(inplace=True, axis=0)

    if len(occurrences) == 0:
        return None

    events = find_events_occurrences(data, labels, occurrences, period, Tep)

    # Find the numbers of columns needed for the graphs
    # Find the number max of events in a occurrence

    period_ids = events[&#39;period_id&#39;].unique().astype(int)

    # Build a list of occurrences events list to build the graph
    events_occurrences_lists = []

    graph_nodes_labels = []
    for period_id in period_ids:
        period_list = []
        period_df = events[events.period_id == period_id]
        i = 0
        for index, event_row in period_df.iterrows():
            new_label = event_row[&#39;label&#39;] + &#39;_&#39; + str(i)
            events.at[index, &#39;label&#39;] = new_label
            period_list.append(new_label)
            i += 1
        graph_nodes_labels += period_list
        events_occurrences_lists.append(period_list)

    # Set of graph_nodes for the graphs
    graph_nodes_labels = set(graph_nodes_labels)

    for period_id in range(min(period_ids), max(period_ids) + 1):
        events_occurrences_lists.append(events.loc[events.period_id == period_id, &#39;label&#39;].tolist())

    graph_nodes, graph_labels, prob_matrix = build_probability_acyclic_graph(labels, graph_nodes_labels,
                                                                             events_occurrences_lists)

    # Build the time distance_matrix
    events.loc[:, &#34;relative_date&#34;] = events.date.apply(lambda x: modulo_datetime(x.to_pydatetime(), period))
    events[&#39;is_last_event&#39;] = events[&#39;period_id&#39;] != events[&#39;period_id&#39;].shift(-1)
    events[&#39;is_first_event&#39;] = events[&#39;period_id&#39;] != events[&#39;period_id&#39;].shift(1)
    events[&#39;next_label&#39;] = events[&#39;label&#39;].shift(-1).fillna(&#39;_nan&#39;).apply(Acyclic_Graph.Acyclic_Graph.node2label)
    events[&#39;next_date&#39;] = events[&#39;date&#39;].shift(-1)
    events[&#39;inter_event_duration&#39;] = events[&#39;next_date&#39;] - events[&#39;end_date&#39;]
    events[&#39;inter_event_duration&#39;] = events[&#39;inter_event_duration&#39;].apply(lambda x: x.total_seconds())
    # events = events[events.is_last_event == False]

    n = len(graph_nodes)  # Nb rows of the prob distance_matrix
    l = len(graph_labels)  # Nb columns of the prob distance_matrix

    # n x l edges for waiting time transition laws
    time_matrix = [[[] for j in range(l)] for i in
                   range(n)]  # Empty lists, [[mean_time, std_time], ...] transition durations

    for i in range(n):
        for j in range(l - 1):  # We dont need the &#34;END NODE&#34;
            if prob_matrix[i][j] != 0:  # Useless to compute time for never happening transition
                from_node = graph_nodes[i]
                to_label = graph_labels[j]

                if from_node == Acyclic_Graph.Acyclic_Graph.START_NODE:  # START_NODE transitions
                    time_df = events.loc[(events.next_label == to_label) &amp; (events.is_first_event == True)]

                    inter_events_durations = time_df.relative_date.values

                else:
                    time_df = events.loc[(events.label == from_node) &amp; (events.next_label == to_label)]
                    inter_events_durations = time_df.inter_event_duration.values

                # We remove NaN from the values
                inter_events_durations = inter_events_durations[~np.isnan(inter_events_durations)]
                inter_events_durations = clean_data_arrays(inter_events_durations)
                time_matrix[i][j] = (&#39;norm&#39;, [np.mean(inter_events_durations), np.std(inter_events_durations)])

    events[&#39;activity_duration&#39;] = events[&#39;end_date&#39;] - events[&#39;date&#39;]
    events[&#39;activity_duration&#39;] = events[&#39;activity_duration&#39;].apply(lambda x: x.total_seconds())

    duration_matrix = [[] for i in range(n)]  # Empty lists, [[mean_time, std_time], ...] Activity duration
    for i in range(n):
        node = graph_nodes[i]
        if node != Acyclic_Graph.Acyclic_Graph.START_NODE:
            time_df = events.loc[events.label == node]
            activity_durations = time_df.activity_duration.values
            # We remove NaN from the values
            activity_durations = activity_durations[~np.isnan(activity_durations)]
            if len(activity_durations) &gt; 0:
                activity_durations = clean_data_arrays(activity_durations)
                # plt.figure()
                # sns.distplot(activity_durations)
                # plt.show()
                duration_matrix[i] = (&#39;norm&#39;, [np.mean(activity_durations), np.std(activity_durations)])

    acyclic_graph = Acyclic_Graph.Acyclic_Graph(graph_nodes, labels, period, prob_matrix, time_matrix, duration_matrix)

    if display_graph:
        acyclic_graph.display(output_folder=output_directory, debug=True)

    return acyclic_graph


def build_probability_acyclic_graph(labels, graph_nodes_labels, occurrence_list):
    &#39;&#39;&#39;
    Build the acyclic graph
    :param graph_labels: Labels of the pattern
    :param graph_nodes_labels: Pattern labels
    :param occurrence_list: List of list of ordered events per occurrence
    :return: Probability transition distance_matrix size = nb(graph_nodes) x nb(labels)
    &#39;&#39;&#39;

    list_length = [len(l) for l in occurrence_list]

    nodes = [Acyclic_Graph.Acyclic_Graph.START_NODE]
    nodes += graph_nodes_labels

    graph_labels = labels + [Acyclic_Graph.Acyclic_Graph.NONE_NODE]

    n = len(nodes)  # Size of the transition distance_matrix
    l = len(graph_labels)

    prob_matrix = np.zeros((n, l))

    # Deal with the beginning of the graph
    single_list = []
    non_occurrences = 0
    for list in occurrence_list:
        if list:
            single_list.append(list[0])
        else:
            non_occurrences += 1

    for node in set(single_list):
        label = Acyclic_Graph.Acyclic_Graph.node2label(node)
        prob_matrix[0][graph_labels.index(label)] = single_list.count(node) / len(occurrence_list)

    prob_matrix[0][l - 1] = non_occurrences / len(occurrence_list)

    for i in range(n - 2):
        tuple_list = []
        single_list = []
        for list in occurrence_list:
            if len(list) &gt; i + 1:
                tuple_list.append(list[i: i + 2])
                single_list.append(list[i])

        for node_1 in set(single_list):
            # Count the number of tuple_list starting by &#39;label_1&#39;
            nb_max = sum([1 if list[0] == node_1 else 0 for list in tuple_list])
            for node_2 in graph_nodes_labels:
                # Count the number of tuple_list starting by &#39;label_1&#39; and finishing by &#39;label_2&#39;
                nb = sum([1 if list == [node_1, node_2] else 0 for list in tuple_list])
                label_2 = Acyclic_Graph.Acyclic_Graph.node2label(node_2)
                p = nb / nb_max
                if p != 0:
                    prob_matrix[nodes.index(node_1)][graph_labels.index(label_2)] = p

    # Checking the validity of the transition (sum output = 1 OR 0)

    tol = 0.001  # Error tolerance
    for i in range(n):
        # Row
        s_row = prob_matrix[i, :].sum()
        if abs(s_row - 1) &gt; tol and s_row != 0:
            raise ValueError(
                &#39;The sum of the probabilities transition from {} is neither 1 nor 0: {}&#39;.format(nodes[i], s_row))

    return nodes, graph_labels, prob_matrix


def clean_data_arrays(data_array):
    &#34;&#34;&#34;
    Clean the data by removing the outliers
    :param data_array:
    :return:
    &#34;&#34;&#34;
    if len(data_array) &lt; 2:
        return data_array

    eps = np.std(data_array) / 2
    db = DBSCAN(eps=eps, min_samples=2, p=1).fit(
        np.asarray(data_array).reshape(-1, 1))
    if len(db.components_) &gt; 0:
        data_array = db.components_

    return data_array


def compute_activity_compatibility_matrix(data):
    activities = list(data.label.unique())
    n = len(activities)

    compatibility_matrix = np.zeros(shape=(n, n))

    for activity in activities:
        activ_df = data.loc[data.label == activity]
        non_activ_df = data.loc[data.label != activity]
        for _, activ_row in activ_df.iterrows():
            start_date = activ_row.date
            end_date = activ_row.end_date
            date_filter = ((non_activ_df.date &lt; start_date) &amp; (non_activ_df.end_date &gt; start_date)) | (
                    (non_activ_df.end_date &gt; end_date) &amp; (non_activ_df.date &lt; end_date)) | (
                                  (non_activ_df.date &gt; start_date) &amp; (non_activ_df.end_date &lt; end_date))

            result = non_activ_df.loc[date_filter]
            if not result.empty:
                result_activities = result.label.unique()
                for result_activity in result_activities:
                    compatibility_matrix[activities.index(activity)][activities.index(result_activity)] += 1

    for i in range(n):
        for j in range(n):
            if compatibility_matrix[i][j] &lt; 5:
                compatibility_matrix[i][j] = 0
            else:
                compatibility_matrix[i][j] = 1
    return activities, compatibility_matrix


def find_events_occurrences(data, labels, occurrences, period, Tep):
    &#39;&#39;&#39;
    Find the events included in the pattern occurrences
    :param data: Input Sequence
    :param labels: labels of the pattern
    :param occurrences: Occurrences of the pattern
    :param period: Frequency of the pattern
    :param Tep: is the time duration max between labels in the same occurrence
    :return: A Dataframe of events included in the occurrences. Columns : [&#39;date&#39;, &#39;label&#39;, &#39;period_id&#39;]
    &#39;&#39;&#39;

    Tep = dt.timedelta(minutes=Tep)

    # Result dataframe
    events = pd.DataFrame(columns=[&#34;date&#34;, &#34;label&#34;, &#34;period_id&#34;])

    start_time = occurrences.date.min().to_pydatetime()
    start_date_first_period = start_time - dt.timedelta(
        seconds=modulo_datetime(start_time, period))

    end_time = occurrences.date.max().to_pydatetime()
    start_date_last_period = end_time - dt.timedelta(
        seconds=modulo_datetime(end_time, period))

    data = data.loc[data.label.isin(labels)]

    start_date_current_period = start_date_first_period

    period_id = 0
    while start_date_current_period &lt;= start_date_last_period:
        end_date_current_period = start_date_current_period + period

        date_filter = (occurrences.date &gt;= start_date_current_period) \
                      &amp; (occurrences.date &lt; end_date_current_period)

        occurrence_happened = len(occurrences.loc[date_filter]) &gt; 0
        if occurrence_happened:  # Occurrence happened
            # Fill events Dataframe
            occ_date = occurrences.loc[date_filter].date.min().to_pydatetime()
            occ_end_date = occ_date + Tep
            occ_events = data.loc[(data.date &gt;= occ_date) &amp; (data.date &lt;= occ_end_date)].copy()
            occ_events[&#39;period_id&#39;] = period_id
            events = pd.concat([events, occ_events]).drop_duplicates(keep=False)
            events.reset_index(inplace=True, drop=True)

        period_id += 1
        start_date_current_period = end_date_current_period

    return events


def best_fit_distribution(data, bins=200, ax=None):
    dist_list = [&#39;norm&#39;, &#39;expon&#39;, &#39;lognorm&#39;, &#39;triang&#39;, &#39;beta&#39;, &#39;gaussian_kde&#39;]

    y, x = np.histogram(data, bins=200, density=True)
    x = (x + np.roll(x, -1))[:-1] / 2.0

    best_distribution = &#39;norm&#39;
    best_params = (0.0, 1.0)
    best_sse = np.inf

    for dist_name in dist_list:
        dist = getattr(st, dist_name)
        param = dist.fit(data)  # distribution fitting

        # Separate parts of parameters
        arg = param[:-2]
        loc = param[-2]
        scale = param[-1]

        param = list(param)

        # Calculate fitted PDF and error with fit in distribution
        pdf = dist.pdf(x, loc=loc, scale=scale, *arg)
        sse = np.sum(np.power(y - pdf, 2.0))

        # if axis pass in add to plot
        try:
            if ax:
                pd.Series(pdf, x).plot(ax=ax, legend=True, label=dist_name)
        except Exception:
            pass

        # identify if this distribution is better
        if best_sse &gt; sse &gt; 0:
            best_distribution = dist_name
            best_params = param
            best_sse = sse

    return best_distribution, best_params


if __name__ == &#34;__main__&#34;:
    main()</code></pre>
            </details>
        </section>
        <section>
        </section>
        <section>
        </section>
        <section>
            <h2 class="section-title" id="header-functions">Functions</h2>
            <dl>
                <dt id="Graph_Model.Build_Graph.best_fit_distribution"><code class="name flex">
                    <span>def <span
                            class="ident">best_fit_distribution</span></span>(<span>data, bins=200, ax=None)</span>
                </code></dt>
                <dd>
                    <div class="desc"></div>
                    <details class="source">
                        <summary>
                            <span>Expand source code</span>
                        </summary>
                        <pre><code class="python">def best_fit_distribution(data, bins=200, ax=None):
    dist_list = [&#39;norm&#39;, &#39;expon&#39;, &#39;lognorm&#39;, &#39;triang&#39;, &#39;beta&#39;, &#39;gaussian_kde&#39;]

    y, x = np.histogram(data, bins=200, density=True)
    x = (x + np.roll(x, -1))[:-1] / 2.0

    best_distribution = &#39;norm&#39;
    best_params = (0.0, 1.0)
    best_sse = np.inf

    for dist_name in dist_list:
        dist = getattr(st, dist_name)
        param = dist.fit(data)  # distribution fitting

        # Separate parts of parameters
        arg = param[:-2]
        loc = param[-2]
        scale = param[-1]

        param = list(param)

        # Calculate fitted PDF and error with fit in distribution
        pdf = dist.pdf(x, loc=loc, scale=scale, *arg)
        sse = np.sum(np.power(y - pdf, 2.0))

        # if axis pass in add to plot
        try:
            if ax:
                pd.Series(pdf, x).plot(ax=ax, legend=True, label=dist_name)
        except Exception:
            pass

        # identify if this distribution is better
        if best_sse &gt; sse &gt; 0:
            best_distribution = dist_name
            best_params = param
            best_sse = sse

    return best_distribution, best_params</code></pre>
                    </details>
                </dd>
                <dt id="Graph_Model.Build_Graph.build_graph"><code class="name flex">
                    <span>def <span class="ident">build_graph</span></span>(<span>data, labels, period, start_date, end_date, Tep=30, output_directory='./', display_graph=False)</span>
                </code></dt>
                <dd>
                    <div class="desc"><p>Turn a pattern to a graph
                        :param data: Input log_dataset
                        :param labels: list of labels included in the pattern
                        :param time_description: time description of the pattern {mu1 : sigma1, mu2 : sigma2, &hellip;}
                        :param tolerance_ratio: tolerance ratio to get the expected occurrences
                        :param period : Periodicity of the time description
                        :param start_date :
                        :param end_date :
                        :param Tep : [in Minutes] Maximal time interval between events in an episode occurrence. Should
                        correspond to the maximal duration of the ADLs.
                        :param output_directory Output Directory to save graphs images
                        :return: A transition probability distance_matrix and a transition waiting time distance_matrix
                        for each component of the description</p></div>
                    <details class="source">
                        <summary>
                            <span>Expand source code</span>
                        </summary>
                        <pre><code class="python">def build_graph(data, labels, period, start_date, end_date, Tep=30,
                output_directory=&#39;./&#39;, display_graph=False):
    &#39;&#39;&#39;
    Turn a pattern to a graph
    :param data: Input log_dataset
    :param labels: list of labels included in the pattern
    :param time_description: time description of the pattern {mu1 : sigma1, mu2 : sigma2, ...}
    :param tolerance_ratio: tolerance ratio to get the expected occurrences
    :param period : Periodicity of the time description
    :param start_date :
    :param end_date :
    :param Tep : [in Minutes] Maximal time interval between events in an episode occurrence. Should correspond to the maximal duration of the ADLs.
    :param output_directory Output Directory to save graphs images
    :return: A transition probability distance_matrix and a transition waiting time distance_matrix for each component of the description
    &#39;&#39;&#39;

    data = data.loc[(data.date &gt;= start_date) &amp; (data.date &lt;= end_date)].copy()

    # Find pattern occurrences
    occurrences = find_occurrences(data, tuple(labels), Tep)
    occurrences = occurrences.loc[(occurrences.date &gt;= start_date) &amp; (occurrences.date &lt;= end_date)].copy()

    # Compute relative dates
    # occurrences.loc[:, &#34;relative_date&#34;] = occurrences.date.apply(
    #     lambda x: modulo_datetime(x.to_pydatetime(), period))

    # # Drop unexpected occurrences
    # occurrences[&#34;expected&#34;] = occurrences[&#34;relative_date&#34;].apply(
    #     lambda x: is_occurence_expected(x, {mu_time: sigma_time}, period, tolerance_ratio))
    # occurrences.dropna(inplace=True, axis=0)

    if len(occurrences) == 0:
        return None

    events = find_events_occurrences(data, labels, occurrences, period, Tep)

    # Find the numbers of columns needed for the graphs
    # Find the number max of events in a occurrence

    period_ids = events[&#39;period_id&#39;].unique().astype(int)

    # Build a list of occurrences events list to build the graph
    events_occurrences_lists = []

    graph_nodes_labels = []
    for period_id in period_ids:
        period_list = []
        period_df = events[events.period_id == period_id]
        i = 0
        for index, event_row in period_df.iterrows():
            new_label = event_row[&#39;label&#39;] + &#39;_&#39; + str(i)
            events.at[index, &#39;label&#39;] = new_label
            period_list.append(new_label)
            i += 1
        graph_nodes_labels += period_list
        events_occurrences_lists.append(period_list)

    # Set of graph_nodes for the graphs
    graph_nodes_labels = set(graph_nodes_labels)

    for period_id in range(min(period_ids), max(period_ids) + 1):
        events_occurrences_lists.append(events.loc[events.period_id == period_id, &#39;label&#39;].tolist())

    graph_nodes, graph_labels, prob_matrix = build_probability_acyclic_graph(labels, graph_nodes_labels,
                                                                             events_occurrences_lists)

    # Build the time distance_matrix
    events.loc[:, &#34;relative_date&#34;] = events.date.apply(lambda x: modulo_datetime(x.to_pydatetime(), period))
    events[&#39;is_last_event&#39;] = events[&#39;period_id&#39;] != events[&#39;period_id&#39;].shift(-1)
    events[&#39;is_first_event&#39;] = events[&#39;period_id&#39;] != events[&#39;period_id&#39;].shift(1)
    events[&#39;next_label&#39;] = events[&#39;label&#39;].shift(-1).fillna(&#39;_nan&#39;).apply(Acyclic_Graph.Acyclic_Graph.node2label)
    events[&#39;next_date&#39;] = events[&#39;date&#39;].shift(-1)
    events[&#39;inter_event_duration&#39;] = events[&#39;next_date&#39;] - events[&#39;end_date&#39;]
    events[&#39;inter_event_duration&#39;] = events[&#39;inter_event_duration&#39;].apply(lambda x: x.total_seconds())
    # events = events[events.is_last_event == False]

    n = len(graph_nodes)  # Nb rows of the prob distance_matrix
    l = len(graph_labels)  # Nb columns of the prob distance_matrix

    # n x l edges for waiting time transition laws
    time_matrix = [[[] for j in range(l)] for i in
                   range(n)]  # Empty lists, [[mean_time, std_time], ...] transition durations

    for i in range(n):
        for j in range(l - 1):  # We dont need the &#34;END NODE&#34;
            if prob_matrix[i][j] != 0:  # Useless to compute time for never happening transition
                from_node = graph_nodes[i]
                to_label = graph_labels[j]

                if from_node == Acyclic_Graph.Acyclic_Graph.START_NODE:  # START_NODE transitions
                    time_df = events.loc[(events.next_label == to_label) &amp; (events.is_first_event == True)]

                    inter_events_durations = time_df.relative_date.values

                else:
                    time_df = events.loc[(events.label == from_node) &amp; (events.next_label == to_label)]
                    inter_events_durations = time_df.inter_event_duration.values

                # We remove NaN from the values
                inter_events_durations = inter_events_durations[~np.isnan(inter_events_durations)]
                inter_events_durations = clean_data_arrays(inter_events_durations)
                time_matrix[i][j] = (&#39;norm&#39;, [np.mean(inter_events_durations), np.std(inter_events_durations)])

    events[&#39;activity_duration&#39;] = events[&#39;end_date&#39;] - events[&#39;date&#39;]
    events[&#39;activity_duration&#39;] = events[&#39;activity_duration&#39;].apply(lambda x: x.total_seconds())

    duration_matrix = [[] for i in range(n)]  # Empty lists, [[mean_time, std_time], ...] Activity duration
    for i in range(n):
        node = graph_nodes[i]
        if node != Acyclic_Graph.Acyclic_Graph.START_NODE:
            time_df = events.loc[events.label == node]
            activity_durations = time_df.activity_duration.values
            # We remove NaN from the values
            activity_durations = activity_durations[~np.isnan(activity_durations)]
            if len(activity_durations) &gt; 0:
                activity_durations = clean_data_arrays(activity_durations)
                # plt.figure()
                # sns.distplot(activity_durations)
                # plt.show()
                duration_matrix[i] = (&#39;norm&#39;, [np.mean(activity_durations), np.std(activity_durations)])

    acyclic_graph = Acyclic_Graph.Acyclic_Graph(graph_nodes, labels, period, prob_matrix, time_matrix, duration_matrix)

    if display_graph:
        acyclic_graph.display(output_folder=output_directory, debug=True)

    return acyclic_graph</code></pre>
                    </details>
                </dd>
                <dt id="Graph_Model.Build_Graph.build_probability_acyclic_graph"><code class="name flex">
                    <span>def <span class="ident">build_probability_acyclic_graph</span></span>(<span>labels, graph_nodes_labels, occurrence_list)</span>
                </code></dt>
                <dd>
                    <div class="desc"><p>Build the acyclic graph
                        :param graph_labels: Labels of the pattern
                        :param graph_nodes_labels: Pattern labels
                        :param occurrence_list: List of list of ordered events per occurrence
                        :return: Probability transition distance_matrix size = nb(graph_nodes) x nb(labels)</p></div>
                    <details class="source">
                        <summary>
                            <span>Expand source code</span>
                        </summary>
                        <pre><code class="python">def build_probability_acyclic_graph(labels, graph_nodes_labels, occurrence_list):
    &#39;&#39;&#39;
    Build the acyclic graph
    :param graph_labels: Labels of the pattern
    :param graph_nodes_labels: Pattern labels
    :param occurrence_list: List of list of ordered events per occurrence
    :return: Probability transition distance_matrix size = nb(graph_nodes) x nb(labels)
    &#39;&#39;&#39;

    list_length = [len(l) for l in occurrence_list]

    nodes = [Acyclic_Graph.Acyclic_Graph.START_NODE]
    nodes += graph_nodes_labels

    graph_labels = labels + [Acyclic_Graph.Acyclic_Graph.NONE_NODE]

    n = len(nodes)  # Size of the transition distance_matrix
    l = len(graph_labels)

    prob_matrix = np.zeros((n, l))

    # Deal with the beginning of the graph
    single_list = []
    non_occurrences = 0
    for list in occurrence_list:
        if list:
            single_list.append(list[0])
        else:
            non_occurrences += 1

    for node in set(single_list):
        label = Acyclic_Graph.Acyclic_Graph.node2label(node)
        prob_matrix[0][graph_labels.index(label)] = single_list.count(node) / len(occurrence_list)

    prob_matrix[0][l - 1] = non_occurrences / len(occurrence_list)

    for i in range(n - 2):
        tuple_list = []
        single_list = []
        for list in occurrence_list:
            if len(list) &gt; i + 1:
                tuple_list.append(list[i: i + 2])
                single_list.append(list[i])

        for node_1 in set(single_list):
            # Count the number of tuple_list starting by &#39;label_1&#39;
            nb_max = sum([1 if list[0] == node_1 else 0 for list in tuple_list])
            for node_2 in graph_nodes_labels:
                # Count the number of tuple_list starting by &#39;label_1&#39; and finishing by &#39;label_2&#39;
                nb = sum([1 if list == [node_1, node_2] else 0 for list in tuple_list])
                label_2 = Acyclic_Graph.Acyclic_Graph.node2label(node_2)
                p = nb / nb_max
                if p != 0:
                    prob_matrix[nodes.index(node_1)][graph_labels.index(label_2)] = p

    # Checking the validity of the transition (sum output = 1 OR 0)

    tol = 0.001  # Error tolerance
    for i in range(n):
        # Row
        s_row = prob_matrix[i, :].sum()
        if abs(s_row - 1) &gt; tol and s_row != 0:
            raise ValueError(
                &#39;The sum of the probabilities transition from {} is neither 1 nor 0: {}&#39;.format(nodes[i], s_row))

    return nodes, graph_labels, prob_matrix</code></pre>
                    </details>
                </dd>
                <dt id="Graph_Model.Build_Graph.clean_data_arrays"><code class="name flex">
                    <span>def <span class="ident">clean_data_arrays</span></span>(<span>data_array)</span>
                </code></dt>
                <dd>
                    <div class="desc"><p>Clean the data by removing the outliers
                        :param data_array:
                        :return:</p></div>
                    <details class="source">
                        <summary>
                            <span>Expand source code</span>
                        </summary>
                        <pre><code class="python">def clean_data_arrays(data_array):
    &#34;&#34;&#34;
    Clean the data by removing the outliers
    :param data_array:
    :return:
    &#34;&#34;&#34;
    if len(data_array) &lt; 2:
        return data_array

    eps = np.std(data_array) / 2
    db = DBSCAN(eps=eps, min_samples=2, p=1).fit(
        np.asarray(data_array).reshape(-1, 1))
    if len(db.components_) &gt; 0:
        data_array = db.components_

    return data_array</code></pre>
                    </details>
                </dd>
                <dt id="Graph_Model.Build_Graph.compute_activity_compatibility_matrix"><code class="name flex">
                    <span>def <span class="ident">compute_activity_compatibility_matrix</span></span>(<span>data)</span>
                </code></dt>
                <dd>
                    <div class="desc"></div>
                    <details class="source">
                        <summary>
                            <span>Expand source code</span>
                        </summary>
                        <pre><code class="python">def compute_activity_compatibility_matrix(data):
    activities = list(data.label.unique())
    n = len(activities)

    compatibility_matrix = np.zeros(shape=(n, n))

    for activity in activities:
        activ_df = data.loc[data.label == activity]
        non_activ_df = data.loc[data.label != activity]
        for _, activ_row in activ_df.iterrows():
            start_date = activ_row.date
            end_date = activ_row.end_date
            date_filter = ((non_activ_df.date &lt; start_date) &amp; (non_activ_df.end_date &gt; start_date)) | (
                    (non_activ_df.end_date &gt; end_date) &amp; (non_activ_df.date &lt; end_date)) | (
                                  (non_activ_df.date &gt; start_date) &amp; (non_activ_df.end_date &lt; end_date))

            result = non_activ_df.loc[date_filter]
            if not result.empty:
                result_activities = result.label.unique()
                for result_activity in result_activities:
                    compatibility_matrix[activities.index(activity)][activities.index(result_activity)] += 1

    for i in range(n):
        for j in range(n):
            if compatibility_matrix[i][j] &lt; 5:
                compatibility_matrix[i][j] = 0
            else:
                compatibility_matrix[i][j] = 1
    return activities, compatibility_matrix</code></pre>
                    </details>
                </dd>
                <dt id="Graph_Model.Build_Graph.find_events_occurrences"><code class="name flex">
                    <span>def <span class="ident">find_events_occurrences</span></span>(<span>data, labels, occurrences, period, Tep)</span>
                </code></dt>
                <dd>
                    <div class="desc"><p>Find the events included in the pattern occurrences
                        :param data: Input Sequence
                        :param labels: labels of the pattern
                        :param occurrences: Occurrences of the pattern
                        :param period: Frequency of the pattern
                        :param Tep: is the time duration max between labels in the same occurrence
                        :return: A Dataframe of events included in the occurrences. Columns : ['date', 'label',
                        'period_id']</p></div>
                    <details class="source">
                        <summary>
                            <span>Expand source code</span>
                        </summary>
                        <pre><code class="python">def find_events_occurrences(data, labels, occurrences, period, Tep):
    &#39;&#39;&#39;
    Find the events included in the pattern occurrences
    :param data: Input Sequence
    :param labels: labels of the pattern
    :param occurrences: Occurrences of the pattern
    :param period: Frequency of the pattern
    :param Tep: is the time duration max between labels in the same occurrence
    :return: A Dataframe of events included in the occurrences. Columns : [&#39;date&#39;, &#39;label&#39;, &#39;period_id&#39;]
    &#39;&#39;&#39;

    Tep = dt.timedelta(minutes=Tep)

    # Result dataframe
    events = pd.DataFrame(columns=[&#34;date&#34;, &#34;label&#34;, &#34;period_id&#34;])

    start_time = occurrences.date.min().to_pydatetime()
    start_date_first_period = start_time - dt.timedelta(
        seconds=modulo_datetime(start_time, period))

    end_time = occurrences.date.max().to_pydatetime()
    start_date_last_period = end_time - dt.timedelta(
        seconds=modulo_datetime(end_time, period))

    data = data.loc[data.label.isin(labels)]

    start_date_current_period = start_date_first_period

    period_id = 0
    while start_date_current_period &lt;= start_date_last_period:
        end_date_current_period = start_date_current_period + period

        date_filter = (occurrences.date &gt;= start_date_current_period) \
                      &amp; (occurrences.date &lt; end_date_current_period)

        occurrence_happened = len(occurrences.loc[date_filter]) &gt; 0
        if occurrence_happened:  # Occurrence happened
            # Fill events Dataframe
            occ_date = occurrences.loc[date_filter].date.min().to_pydatetime()
            occ_end_date = occ_date + Tep
            occ_events = data.loc[(data.date &gt;= occ_date) &amp; (data.date &lt;= occ_end_date)].copy()
            occ_events[&#39;period_id&#39;] = period_id
            events = pd.concat([events, occ_events]).drop_duplicates(keep=False)
            events.reset_index(inplace=True, drop=True)

        period_id += 1
        start_date_current_period = end_date_current_period

    return events</code></pre>
                    </details>
                </dd>
                <dt id="Graph_Model.Build_Graph.main"><code class="name flex">
                    <span>def <span class="ident">main</span></span>(<span>)</span>
                </code></dt>
                <dd>
                    <div class="desc"></div>
                    <details class="source">
                        <summary>
                            <span>Expand source code</span>
                        </summary>
                        <pre><code class="python">def main():
    dataset_name = &#39;aruba&#39;

    dataset = pick_dataset(dataset_name, nb_days=120)

    output = &#34;../output/{}/ID_0&#34;.format(dataset_name)
    patterns = pickle.load(open(output + &#39;/patterns.pickle&#39;, &#39;rb&#39;))

    # Drop duplicates episodes
    patterns.drop_duplicates(subset=[&#39;Episode&#39;], keep=&#39;first&#39;, inplace=True)

    # patterns = patterns[:2]

    start_date = dataset.date.min().to_pydatetime()
    end_date = dataset.date.max().to_pydatetime()

    simulation_result = pd.DataFrame(columns=[&#39;date&#39;, &#39;end_date&#39;, &#39;label&#39;])
    all_graphs = []

    # Add graphs coming from patterns
    for _, pattern in patterns.iterrows():
        labels = list(pattern[&#39;Episode&#39;])
        period = pattern[&#39;Period&#39;]
        description = pattern[&#39;Description&#39;]
        output_folder = output + &#34;/Patterns_Graph/&#34; + &#34;_&#34;.join(labels) + &#34;/&#34;

        if not os.path.exists(os.path.dirname(output_folder)):
            try:
                os.makedirs(os.path.dirname(output_folder))
            except OSError as exc:  # Guard against race condition
                if exc.errno != errno.EEXIST:
                    raise

        start_time = t.process_time()  # To compute time spent building the graph

        pattern_graph = build_graph(data=dataset, labels=labels, period=period,
                                    start_date=start_date, end_date=end_date, output_directory=output_folder,
                                    display_graph=True)
        elapsed_time = dt.timedelta(seconds=round(t.process_time() - start_time, 1))

        print(&#34;\n&#34;)
        print(&#34;###############################&#34;)
        print(&#34;Patterns turned into graphs. Elapsed time : {}&#34;.format(elapsed_time))
        print(&#34;##############################&#34;)
        print(&#34;\n&#34;)

        all_graphs.append(pattern_graph)

    # Add graphs coming from unusual events

    data_left = pickle.load(open(output + &#39;/data_left.pickle&#39;, &#39;rb&#39;))

    activities = data_left.label.unique()</code></pre>
                    </details>
                </dd>
            </dl>
        </section>
        <section>
        </section>
    </article>
    <nav id="sidebar">
        <h1>Index</h1>
        <div class="toc">
            <ul></ul>
        </div>
        <ul id="index">
            <li><h3>Super-module</h3>
                <ul>
                    <li><code><a href="index.html" title="Graph_Model">Graph_Model</a></code></li>
                </ul>
            </li>
            <li><h3><a href="#header-functions">Functions</a></h3>
                <ul class="">
                    <li><code><a href="#Graph_Model.Build_Graph.best_fit_distribution"
                                 title="Graph_Model.Build_Graph.best_fit_distribution">best_fit_distribution</a></code>
                    </li>
                    <li><code><a href="#Graph_Model.Build_Graph.build_graph"
                                 title="Graph_Model.Build_Graph.build_graph">build_graph</a></code></li>
                    <li><code><a href="#Graph_Model.Build_Graph.build_probability_acyclic_graph"
                                 title="Graph_Model.Build_Graph.build_probability_acyclic_graph">build_probability_acyclic_graph</a></code>
                    </li>
                    <li><code><a href="#Graph_Model.Build_Graph.clean_data_arrays"
                                 title="Graph_Model.Build_Graph.clean_data_arrays">clean_data_arrays</a></code></li>
                    <li><code><a href="#Graph_Model.Build_Graph.compute_activity_compatibility_matrix"
                                 title="Graph_Model.Build_Graph.compute_activity_compatibility_matrix">compute_activity_compatibility_matrix</a></code>
                    </li>
                    <li><code><a href="#Graph_Model.Build_Graph.find_events_occurrences"
                                 title="Graph_Model.Build_Graph.find_events_occurrences">find_events_occurrences</a></code>
                    </li>
                    <li><code><a href="#Graph_Model.Build_Graph.main"
                                 title="Graph_Model.Build_Graph.main">main</a></code></li>
                </ul>
            </li>
        </ul>
    </nav>
</main>
<footer id="footer">
    <p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>