{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sys \n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"./FP_Growth\"))\n",
    "import fp_growth\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Exploration of the Toy Dataset</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"toy_dataset.txt\", delimiter=';')\n",
    "form = '%Y-%d-%m %H:%M'\n",
    "df['date'] = pd.to_datetime(df['date'], format=form)\n",
    "df = df.set_index('date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-11-29 07:51:00</th>\n",
       "      <td>kitchen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-29 07:59:00</th>\n",
       "      <td>breakfast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-29 08:02:00</th>\n",
       "      <td>coffee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-29 12:42:00</th>\n",
       "      <td>kitchen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-29 12:46:00</th>\n",
       "      <td>lunch</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      activity\n",
       "date                          \n",
       "2017-11-29 07:51:00    kitchen\n",
       "2017-11-29 07:59:00  breakfast\n",
       "2017-11-29 08:02:00     coffee\n",
       "2017-11-29 12:42:00    kitchen\n",
       "2017-11-29 12:46:00      lunch"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['kitchen', 'breakfast', 'coffee'], ['kitchen', 'lunch', 'coffee'], ['kitchen', 'breakfast', 'coffee'], ['kitchen', 'lunch', 'coffee'], ['kitchen', 'breakfast', 'coffee'], ['kitchen', 'lunch'], ['kitchen', 'breakfast', 'coffee'], ['kitchen', 'lunch', 'coffee']]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activity</th>\n",
       "      <th>trans_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-11-29 07:51:00</th>\n",
       "      <td>kitchen</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-29 07:59:00</th>\n",
       "      <td>breakfast</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-29 08:02:00</th>\n",
       "      <td>coffee</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-29 12:42:00</th>\n",
       "      <td>kitchen</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-29 12:46:00</th>\n",
       "      <td>lunch</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-29 13:06:00</th>\n",
       "      <td>coffee</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-30 07:43:00</th>\n",
       "      <td>kitchen</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-30 07:57:00</th>\n",
       "      <td>breakfast</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-30 08:02:00</th>\n",
       "      <td>coffee</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-30 12:02:00</th>\n",
       "      <td>kitchen</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-30 12:15:00</th>\n",
       "      <td>lunch</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-30 12:22:00</th>\n",
       "      <td>coffee</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-01 08:01:00</th>\n",
       "      <td>kitchen</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-01 08:05:00</th>\n",
       "      <td>breakfast</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-01 08:07:00</th>\n",
       "      <td>coffee</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-01 12:57:00</th>\n",
       "      <td>kitchen</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-01 13:05:00</th>\n",
       "      <td>lunch</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-02 08:19:00</th>\n",
       "      <td>kitchen</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-02 08:20:00</th>\n",
       "      <td>breakfast</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-02 08:23:00</th>\n",
       "      <td>coffee</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-02 12:30:00</th>\n",
       "      <td>kitchen</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-02 12:37:00</th>\n",
       "      <td>lunch</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-02 13:05:00</th>\n",
       "      <td>coffee</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      activity  trans_id\n",
       "date                                    \n",
       "2017-11-29 07:51:00    kitchen         1\n",
       "2017-11-29 07:59:00  breakfast         1\n",
       "2017-11-29 08:02:00     coffee         1\n",
       "2017-11-29 12:42:00    kitchen         2\n",
       "2017-11-29 12:46:00      lunch         2\n",
       "2017-11-29 13:06:00     coffee         2\n",
       "2017-11-30 07:43:00    kitchen         3\n",
       "2017-11-30 07:57:00  breakfast         3\n",
       "2017-11-30 08:02:00     coffee         3\n",
       "2017-11-30 12:02:00    kitchen         4\n",
       "2017-11-30 12:15:00      lunch         4\n",
       "2017-11-30 12:22:00     coffee         4\n",
       "2017-12-01 08:01:00    kitchen         5\n",
       "2017-12-01 08:05:00  breakfast         5\n",
       "2017-12-01 08:07:00     coffee         5\n",
       "2017-12-01 12:57:00    kitchen         6\n",
       "2017-12-01 13:05:00      lunch         6\n",
       "2017-12-02 08:19:00    kitchen         7\n",
       "2017-12-02 08:20:00  breakfast         7\n",
       "2017-12-02 08:23:00     coffee         7\n",
       "2017-12-02 12:30:00    kitchen         8\n",
       "2017-12-02 12:37:00      lunch         8\n",
       "2017-12-02 13:05:00     coffee         8"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def extract_transactions(df, Tep = 30) :\n",
    "    \"\"\"\n",
    "    Tep: in minutes\n",
    "    \"\"\"\n",
    "    \n",
    "    tep_days = int(math.floor(Tep/60))\n",
    "    tep_minutes = Tep - tep_days*60\n",
    "    start_time = df.index[0] #Start time of the dataset\n",
    "\n",
    "    df['trans_id'] = 0\n",
    "    # Tep = 30mn, Max time for an activity (episode occurrence)\n",
    "    current_start_time = start_time\n",
    "    current_trans_id = 0\n",
    "\n",
    "    transactions = []\n",
    "    while True:\n",
    "        current_trans_id += 1\n",
    "        current_end_time = current_start_time + dt.timedelta(hours=tep_days, minutes=tep_minutes)\n",
    "        transactions.append(list(df.loc[(df.index >= current_start_time) & (df.index < current_end_time)].activity.values))\n",
    "        df.loc[(df.index >= current_start_time) & (df.index < current_end_time), 'trans_id'] = current_trans_id\n",
    "\n",
    "        if len(df.loc[df.index > current_end_time]) > 0 :\n",
    "            current_start_time =  df.loc[df.index > current_end_time].index[0]\n",
    "        else :\n",
    "            break\n",
    "    \n",
    "    return df, transactions\n",
    "\n",
    "df, transactions = extract_transactions(df, Tep=60)\n",
    "print(transactions)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('breakfast', 'coffee'): 4, ('breakfast', 'coffee', 'kitchen'): 4, ('coffee', 'kitchen', 'lunch'): 3, ('kitchen', 'lunch'): 4, ('coffee', 'kitchen'): 7, ('kitchen',): 8}\n"
     ]
    }
   ],
   "source": [
    "episodes_dict = fp_growth.find_frequent_patterns(transactions, 2)\n",
    "print(episodes_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_occurrences(df, occurrences_df, episode):\n",
    "    occ_trans_id = list(df.trans_id.unique())\n",
    "    for item in episode:\n",
    "        occ_trans_id = list(set(occ_trans_id).intersection(list(df[df.activity == item].trans_id.unique())))\n",
    "    \n",
    "    for id in occ_trans_id:\n",
    "        start_time = min(df[(df.trans_id == id) & (df.activity.isin(episode))].index) #First event of the episode\n",
    "        end_time = max(df[(df.trans_id == id) & (df.activity.isin(episode))].index) #Last event of the episode\n",
    "        occurrences_df.loc[len(occurrences_df)+1] = [episode, start_time, end_time]\n",
    "    \n",
    "    return occ_trans_id\n",
    "\n",
    "def modulo_datetime(date, period):\n",
    "    \"\"\"\n",
    "    @date: datetime.datetime object\n",
    "    @period : datetime.timedelta\n",
    "    \"\"\"\n",
    "    seconds = int((date - dt.datetime.min).total_seconds())\n",
    "    remainder = dt.timedelta(\n",
    "        seconds = seconds % period.total_seconds(),\n",
    "        microseconds = date.microsecond,\n",
    "    )\n",
    "    return remainder\n",
    "\n",
    "def occurence_expected(occ_start_time, descr_dict, tolerance_ratio = 1):\n",
    "    \n",
    "    for mean_time in descr_dict.keys():\n",
    "        if abs(occ_start_time - mean_time) < tolerance_ratio*descr_dict[mean_time]:\n",
    "            return True\n",
    "        \n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Candidate study step</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>episode</th>\n",
       "      <th>gmm_descr_str</th>\n",
       "      <th>gmm_descr</th>\n",
       "      <th>accuraccy</th>\n",
       "      <th>delta_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(breakfast, coffee)</td>\n",
       "      <td>{'8:05:15': '0:09:00.624639'}</td>\n",
       "      <td>{29115.0: 540.624638729}</td>\n",
       "      <td>1.000</td>\n",
       "      <td>3 days 00:21:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(breakfast, coffee, kitchen)</td>\n",
       "      <td>{'7:58:30': '0:13:26.659780'}</td>\n",
       "      <td>{28710.0: 806.659779586}</td>\n",
       "      <td>1.000</td>\n",
       "      <td>3 days 00:28:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(coffee, kitchen, lunch)</td>\n",
       "      <td>{'12:24:40': '0:16:45.584407'}</td>\n",
       "      <td>{44680.0: 1005.5844072}</td>\n",
       "      <td>0.750</td>\n",
       "      <td>2 days 23:48:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(kitchen, lunch)</td>\n",
       "      <td>{'12:32:45': '0:20:09.989669'}</td>\n",
       "      <td>{45165.0: 1209.98966938}</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2 days 23:48:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(coffee, kitchen)</td>\n",
       "      <td>{'12:24:40': '0:16:45.584407', '7:58:30': '0:1...</td>\n",
       "      <td>{44680.0: 1005.5844072, 28710.0: 806.659779586}</td>\n",
       "      <td>0.875</td>\n",
       "      <td>3 days 04:39:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(kitchen,)</td>\n",
       "      <td>{'7:58:30': '0:13:26.659780', '12:32:45': '0:2...</td>\n",
       "      <td>{28710.0: 806.659779586, 45165.0: 1209.98966938}</td>\n",
       "      <td>1.000</td>\n",
       "      <td>3 days 04:39:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        episode  \\\n",
       "1           (breakfast, coffee)   \n",
       "2  (breakfast, coffee, kitchen)   \n",
       "3      (coffee, kitchen, lunch)   \n",
       "4              (kitchen, lunch)   \n",
       "5             (coffee, kitchen)   \n",
       "6                    (kitchen,)   \n",
       "\n",
       "                                       gmm_descr_str  \\\n",
       "1                      {'8:05:15': '0:09:00.624639'}   \n",
       "2                      {'7:58:30': '0:13:26.659780'}   \n",
       "3                     {'12:24:40': '0:16:45.584407'}   \n",
       "4                     {'12:32:45': '0:20:09.989669'}   \n",
       "5  {'12:24:40': '0:16:45.584407', '7:58:30': '0:1...   \n",
       "6  {'7:58:30': '0:13:26.659780', '12:32:45': '0:2...   \n",
       "\n",
       "                                          gmm_descr  accuraccy         delta_t  \n",
       "1                          {29115.0: 540.624638729}      1.000 3 days 00:21:00  \n",
       "2                          {28710.0: 806.659779586}      1.000 3 days 00:28:00  \n",
       "3                           {44680.0: 1005.5844072}      0.750 2 days 23:48:00  \n",
       "4                          {45165.0: 1209.98966938}      1.000 2 days 23:48:00  \n",
       "5   {44680.0: 1005.5844072, 28710.0: 806.659779586}      0.875 3 days 04:39:00  \n",
       "6  {28710.0: 806.659779586, 45165.0: 1209.98966938}      1.000 3 days 04:39:00  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_time_length = (max(df.index.values) - min(df.index.values))/np.timedelta64(1, 's')\n",
    "\n",
    "\n",
    "#Dataframe for every episodes occurrences, each row is an occurrence for a specific episode\n",
    "occurrences_df = pd.DataFrame(columns = ['episode', 'start_time', 'end_time'])\n",
    "\n",
    "for episode in episodes_dict.keys() :\n",
    "    #print(\"Episode :\", episode, \"Support:\", episodes_dict[episode])\n",
    "    find_occurrences(df, occurrences_df, episode)\n",
    "\n",
    "#Candidates periods for GMM (only T=24hours for now)\n",
    "candidate_periods = [dt.timedelta(days=1)]\n",
    "\n",
    "\n",
    "#INPUTS\n",
    "# Occurences_df : a dataframe with all episodes occurences sorted by start_time\n",
    "# delta_T_max : If there is a gap > deltaTmax between two occurrences of an episode, \n",
    "#            the occurrences before and after the gap are split (different validity intervals). [3 times the candidate period]\n",
    "# support_treshold : minimal support\n",
    "# std_max : maximal standard deviation considered as normal (~10% of the period)\n",
    "# accuracy_min : Minimal accuracy for a periodicity description to be considered as\n",
    "#               interesting, and thus factorized.\n",
    "\n",
    "support_treshold = 2\n",
    "accuracy_min = 0.5\n",
    "std_max = 2\n",
    "\n",
    "episode_best_descr_df = pd.DataFrame(columns = ['episode', 'gmm_descr_str', 'gmm_descr', 'accuraccy', 'delta_t'])\n",
    "\n",
    "for candidate_period in candidate_periods:\n",
    "    cand_occurrences_df = occurrences_df.copy(deep=True)\n",
    "    delta_T_max = 3*candidate_period #mentionned in the INPUTS\n",
    "    std_max = candidate_period.total_seconds()/10\n",
    "    \n",
    "\n",
    "    for episode in episodes_dict.keys() :\n",
    "        occ_df = cand_occurrences_df.loc[occurrences_df.episode == episode]\n",
    "        occ_df = occ_df.sort_values([\"start_time\", \"end_time\"], ascending=True)\n",
    "\n",
    "        #Compute time interval since the last occurence\n",
    "        cand_occurrences_df.loc[cand_occurrences_df.episode == episode, \"time_since_last_occ\"] = occ_df['start_time'] - occ_df['end_time'].shift(1)\n",
    "\n",
    "        #First row 'time_since_last_occ' is NaT so we replace by a duration of '0'\n",
    "        cand_occurrences_df.fillna(0, inplace=True)\n",
    "        \n",
    "        #Compute the relative start time\n",
    "        cand_occurrences_df.loc[:, \"rel_start_time\"] = cand_occurrences_df[\"start_time\"].apply(lambda x : modulo_datetime(x.to_pydatetime(), candidate_period))\n",
    "        occ_df = cand_occurrences_df.loc[cand_occurrences_df.episode == episode]\n",
    "        #Spit the occurrences in groups\n",
    "        group_gap_bounds = [cand_occurrences_df.start_time.min(), cand_occurrences_df.end_time.max()]\n",
    "\n",
    "        # [min_time, insertion of groups bound, max_time]\n",
    "        group_gap_bounds[1:1] = sorted(list(occ_df[occ_df.time_since_last_occ > delta_T_max]['start_time']))\n",
    "        \n",
    "        best_accuracy = 0\n",
    "        best_description = None\n",
    "        best_description_str = None\n",
    "        best_delta_t = None\n",
    "        \n",
    "        \n",
    "        for group_index in range(len(group_gap_bounds)-1):\n",
    "            \n",
    "            group_filter = (cand_occurrences_df.episode == episode) \\\n",
    "            & (cand_occurrences_df.start_time >= group_gap_bounds[group_index]) \\\n",
    "            & (cand_occurrences_df.start_time < group_gap_bounds[group_index+1])\n",
    "            \n",
    "            cand_occurrences_df.loc[group_filter, \"group_id\"] = group_index + 1\n",
    "\n",
    "            occ_rel_start_time_list = cand_occurrences_df.loc[group_filter, \"rel_start_time\"].astype('timedelta64[s]').values\n",
    "            \n",
    "            #X = StandardScaler().fit_transform(occ_rel_start_time_list.reshape(-1, 1))\n",
    "            if(len(occ_rel_start_time_list) == 0):\n",
    "                continue\n",
    "                \n",
    "            #Compute GMM Description\n",
    "            X = occ_rel_start_time_list.reshape(-1, 1)\n",
    "            db = DBSCAN(eps=std_max, min_samples=support_treshold).fit(X)\n",
    "           \n",
    "            N_comp = len(set(db.labels_)) - (1 if -1 in db.labels_ else 0) # Noisy samples are given the label -1. \n",
    "            gmm = GaussianMixture(n_components=N_comp, covariance_type='full')\n",
    "            gmm.fit(X)\n",
    "\n",
    "            episode_gmm_descr = {} # time_mean as key and std as value\n",
    "            episode_gmm_descr_str = {}\n",
    "            for i in range(len(gmm.means_)):\n",
    "                episode_gmm_descr_str[str(dt.timedelta(seconds=gmm.means_[i][0]))] = str(dt.timedelta(seconds=np.sqrt(gmm.covariances_)[i][0][0]))\n",
    "                episode_gmm_descr[gmm.means_[i][0]] = np.sqrt(gmm.covariances_)[i][0][0]\n",
    "            \n",
    "            # Tag the expected occurences\n",
    "            cand_occurrences_df.loc[group_filter, \"expected\"] = cand_occurrences_df.loc[group_filter, \"rel_start_time\"].apply(lambda x : occurence_expected(x.total_seconds(), episode_gmm_descr, std_max))\n",
    "            \n",
    "            #Compute description accuracy\n",
    "            N_occ_exp = N_comp*math.ceil(df_time_length / candidate_period.total_seconds())\n",
    "            \n",
    "            N_occ_exp_and_occ = len(cand_occurrences_df[group_filter & cand_occurrences_df.expected==True])\n",
    "            accuracy = N_occ_exp_and_occ/N_occ_exp\n",
    "            \n",
    "            if(accuracy >= accuracy_min) & (accuracy > best_accuracy):\n",
    "                best_accuracy = accuracy\n",
    "                best_description = episode_gmm_descr\n",
    "                best_description_str = episode_gmm_descr_str\n",
    "                best_delta_t = delta_t = max(cand_occurrences_df.loc[group_filter & cand_occurrences_df.expected==True, \"start_time\"]) \\\n",
    "                - min(list(cand_occurrences_df.loc[group_filter & cand_occurrences_df.expected==True, \"start_time\"]))\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "        episode_best_descr_df.loc[len(episode_best_descr_df)+1] = [episode, best_description_str, best_description, best_accuracy, best_delta_t]    \n",
    "            \n",
    "episode_best_descr_df\n",
    "#pd._libs.tslib.Timestamp.timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Fri Dec  8 16:43:23 2017\n",
    "\n",
    "@author: cyriac.azefack\n",
    "\"\"\"\n",
    "import sys \n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sys.path.append(os.path.abspath(\"./FP_Growth\"))\n",
    "import fp_growth\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def xED_algorithm(data, Tep=30, support_treshold = 2, accuracy_min = 0.5, std_max = 0.1, tolerance_ratio = 2, candidate_periods = [dt.timedelta(days=1)]):\n",
    "    \"\"\"\n",
    "    Implementation of the extended Discovery Algorithm designed by Julie Soulas U{https://hal.archives-ouvertes.fr/tel-01356217/}\n",
    "    \n",
    "    :param data : Starting dataframe, date[datetime] as index and 1 column named \"activity\"\n",
    "    :param Tep : [in Minutes] Maximal time interval between events in an episode occurrence. Should correspond to the maximal duration of the ADLs.\n",
    "    :param support_treshold : [greater than 1] Minimal number of occurrences of an episode, for that episode to be considered as frequent.\n",
    "    :param accuracy_min : [between 0 and 1] Minimal accuracy for a periodicity description to be considered as interesting, and thus factorized\n",
    "    :param std_max : Standard deviation max for a description\n",
    "    :param tolerance_ratio : [greater than 0] An event expected to happen at time t (with standard deviation sigma) occurs as expected if it occurs in the interval [t - tolerance_ratio*sigma, t + tolerance_ratio*sigma]\n",
    "    :param candidate_periods : a list of periods to check for habits periodicity\n",
    "    :return The compressed dataset\n",
    "    \"\"\"\n",
    "    compressed = True\n",
    "    \n",
    "    \n",
    "    while compressed:\n",
    "        \n",
    "        df, transactions = extract_transactions(data, Tep)\n",
    "        \n",
    "        frequent_episodes = fp_growth.find_frequent_patterns(transactions, support_treshold)\n",
    "        \n",
    "        periodicities = {}\n",
    "        \n",
    "        for episode in frequent_episodes.keys():\n",
    "            periodicities[episode] = build_description(df, episode, candidate_periods, \n",
    "                                                           support_treshold, std_max, tolerance_ratio, accuracy_min)\n",
    "        \n",
    "        \n",
    "        return periodicities\n",
    "    \n",
    "\n",
    "\n",
    "def extract_transactions(df, Tep ) :\n",
    "    \"\"\"\n",
    "    Divide the dataframe in transactions subset with max lenth of Tep\n",
    "    :param Tep: in minutes\n",
    "    :return dataset [with a new 'trans_id' column], transactions\n",
    "    \"\"\"\n",
    "    \n",
    "    tep_hours = int(math.floor(Tep/60))\n",
    "    tep_minutes = Tep - tep_hours*60\n",
    "    start_time = min(df.date) #Start time of the dataset\n",
    "\n",
    "    df['trans_id'] = 0\n",
    "\n",
    "    current_start_time = start_time\n",
    "    current_trans_id = 0\n",
    "\n",
    "    transactions = []\n",
    "    while True:\n",
    "        current_trans_id += 1\n",
    "        current_end_time = current_start_time + dt.timedelta(hours=tep_hours, minutes=tep_minutes)\n",
    "        transactions.append(list(df.loc[(df.date >= current_start_time) & (df.date < current_end_time)].activity.values))\n",
    "        df.loc[(df.date >= current_start_time) & (df.date < current_end_time), 'trans_id'] = current_trans_id\n",
    "        \n",
    "        if len(df.loc[df.date > current_end_time]) > 0 :\n",
    "            current_start_time =  min(df.loc[df.date > current_end_time, \"date\"])\n",
    "        else :\n",
    "            break\n",
    "    \n",
    "    return df, transactions\n",
    "\n",
    "def build_description(df, episode, candidate_periods, support_treshold, std_max, tolerance_ratio, accuracy_min):\n",
    "    \"\"\"\n",
    "    Build the best description for all the episodes\n",
    "    :param df : Starting dataframe, date[datetime] as index, columns named \"activity\" and \"trans_id\" (for all the transactions)\n",
    "    :param episode : frequent episode\n",
    "    :param support_treshold : [greater than 1] Minimal number of occurrences of an episode, for that episode to be considered as frequent.\n",
    "    :param std_max : standard deviation max for a period\n",
    "    :param accuracy_min : [between 0 and 1] Minimal accuracy for a periodicity description to be considered as interesting, and thus factorized\n",
    "    :param tolerance_ratio : [greater than 0] An event expected to happen at time t (with standard deviation sigma) occurs as expected if it occurs in the interval [t - tolerance_ratio*sigma, t + tolerance_ratio*sigma]\n",
    "    :return A dataset of episodes with their best description\n",
    "    \"\"\"\n",
    "    \n",
    "    dataset_duration = (max(df.date) - min(df.date))/np.timedelta64(1, 's') #in seconds\n",
    "    \n",
    "    description = {\n",
    "            \"numeric\": {}, #all the components of the description. mean_time as key and std_time as value\n",
    "            \"readable\": {}, #A readable string for the description\n",
    "            \"accuracy\" : 0, #Accuracy of the description\n",
    "            \"delta_t\" : None, # Time duration when the description is valid\n",
    "            \"nb_factorized_events\" : 0,\n",
    "            \"factorized_events_id\" : []\n",
    "            }\n",
    "    \n",
    "    occurences = find_occurences(df, episode)\n",
    "    \n",
    "    for period in candidate_periods:\n",
    "        delta_T_max = 3*period #Gap maximum between two consecutives occurences to be in the same group\n",
    "        occ_period = occurences.copy(deep=True)\n",
    "        occ_period.sort_values([\"start_time\", \"end_time\"], ascending=True, inplace=True)\n",
    "        \n",
    "        #Compute time between occurences\n",
    "        occ_period.loc[:, \"time_since_last_occ\"] = occ_period['start_time'] - occ_period['end_time'].shift(1)\n",
    "        \n",
    "        #First row 'time_since_last_occ' is NaT so we replace by a duration of '0'\n",
    "        occ_period.fillna(0, inplace=True)\n",
    "        \n",
    "        #Compute the relative start time\n",
    "        occ_period.loc[:, \"rel_start_time\"] = occ_period[\"start_time\"].apply(lambda x : modulo_datetime(x.to_pydatetime(), period))\n",
    "       \n",
    "        #Spit the occurrences in groups\n",
    "        group_gap_bounds = [df.date.min(), df.date.max()]\n",
    "        # [min_time, insertion of groups bound, max_time]\n",
    "        group_gap_bounds[1:1] = sorted(list(occ_period[occ_period.time_since_last_occ > delta_T_max]['start_time']))\n",
    "        \n",
    "        for group_index in range(len(group_gap_bounds)-1):\n",
    "            group_filter = (occ_period.start_time >= group_gap_bounds[group_index]) & (occ_period.start_time <= group_gap_bounds[group_index+1])\n",
    "            occ_period.loc[group_filter, 'group_id'] = group_index\n",
    "\n",
    "            #Find the CLUSTERS\n",
    "            data_points = occ_period.loc[group_filter, \"rel_start_time\"].astype('timedelta64[s]').values\n",
    "            if len(data_points) == 0:\n",
    "                continue\n",
    "            \n",
    "            data_points = data_points.reshape(-1, 1)\n",
    "            db = DBSCAN(eps=std_max*period.total_seconds(), min_samples=support_treshold).fit(data_points)\n",
    "           \n",
    "            N_comp = len(set(db.labels_)) - (1 if -1 in db.labels_ else 0) # Noisy samples are given the label -1. \n",
    "            gmm = GaussianMixture(n_components = N_comp, covariance_type='full')\n",
    "            gmm.fit(data_points)\n",
    "\n",
    "            gmm_descr = {} # time_mean as key and std as value\n",
    "            gmm_descr_str = {}\n",
    "            \n",
    "            for i in range(len(gmm.means_)):\n",
    "                gmm_descr_str[str(dt.timedelta(seconds=gmm.means_[i][0]))] = str(dt.timedelta(\n",
    "                        seconds=np.sqrt(gmm.covariances_)[i][0][0]))\n",
    "                gmm_descr[gmm.means_[i][0]] = np.sqrt(gmm.covariances_)[i][0][0]\n",
    "                \n",
    "            \n",
    "            # Tag the expected occurences\n",
    "            occ_period.loc[group_filter, \"expected\"] = occ_period.loc[group_filter, \"rel_start_time\"].apply(\n",
    "                    lambda x : occurence_expected(x.total_seconds(), gmm_descr, tolerance_ratio))\n",
    "            \n",
    "            #Compute description accuracy\n",
    "            N_occ_exp = N_comp * math.ceil(dataset_duration / period.total_seconds())\n",
    "            \n",
    "            N_occ_exp_and_occ = len(occ_period[group_filter & occ_period.expected == True])\n",
    "            accuracy = N_occ_exp_and_occ / N_occ_exp\n",
    "            \n",
    "            \n",
    "                  \n",
    "           \n",
    "            if(accuracy >= accuracy_min) & (accuracy > description[\"accuracy\"]):\n",
    "                description[\"accuracy\"] = accuracy\n",
    "                description[\"numeric\"] = gmm_descr\n",
    "                description[\"readable\"] = gmm_descr_str\n",
    "                description[\"delta_t\"] = max(occ_period.loc[group_filter & occ_period.expected==True, \"start_time\"]) - min(list(occ_period.loc[group_filter & occ_period.expected==True, \"start_time\"]))\n",
    "                description[\"nb_factorized_events\"] = (2 * N_occ_exp_and_occ - N_occ_exp) * len(episode)\n",
    "                description[\"factorized_events_id\"] = list(occ_period.loc[group_filter & (occ_period.expected == True)].index)\n",
    "                \n",
    "    return description\n",
    "\n",
    "def find_occurences(df, episode) :\n",
    "    \"\"\"\n",
    "    return a dataframe of occurences of the episode in the dataframe df\n",
    "    \"\"\"\n",
    "    \n",
    "    occurences = pd.DataFrame(columns = [\"trans_id\", \"start_time\", \"end_time\"])\n",
    "    \n",
    "    occurences_trans_id_list = list(df.trans_id.unique())\n",
    "    for item in episode :\n",
    "        occurences_trans_id_list = list(set(occurences_trans_id_list).intersection(list(\n",
    "                df[df.activity == item].trans_id.unique())))\n",
    "        \n",
    "    for id in occurences_trans_id_list :\n",
    "        start_time = min(df[(df.trans_id == id) & (df.activity.isin(episode))].date) #First event of the episode\n",
    "        end_time = max(df[(df.trans_id == id) & (df.activity.isin(episode))].date) #Last event of the episode\n",
    "        \n",
    "        occurences.loc[len(occurences)] = [id, start_time, end_time]\n",
    "    \n",
    "    \n",
    "    return occurences\n",
    "\n",
    "def modulo_datetime(date, period):\n",
    "    \"\"\"\n",
    "    Compute the relative date in the period\n",
    "    :param date: datetime.datetime object\n",
    "    :param period : datetime.timedelta\n",
    "    \"\"\"\n",
    "    seconds = int((date - dt.datetime.min).total_seconds())\n",
    "    remainder = dt.timedelta(\n",
    "        seconds = seconds % period.total_seconds(),\n",
    "        microseconds = date.microsecond,\n",
    "    )\n",
    "    return remainder\n",
    "\n",
    "def occurence_expected(start_time, description, tolerance_ratio = 1):\n",
    "    \"\"\"\n",
    "    Return True if an occurence is expected to occur according to the description\n",
    "    :param start_time : occurence start time\n",
    "    :param description : description dict with mean times as keys and standard deviations as values\n",
    "    :param tolerance_ratio : tolerable distance to the mean\n",
    "    \"\"\"\n",
    "    for mean_time in description.keys():\n",
    "        if abs(start_time - mean_time) < tolerance_ratio*description[mean_time]:\n",
    "            return True\n",
    "        \n",
    "    return False\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ########################################\n",
    "    # DATA PREPROCESSING\n",
    "    ########################################\n",
    "    \n",
    "    \"\"\"\n",
    "    The dataframe should have 1 index (date as datetime) and 1 feature (activity)\n",
    "    \"\"\"\n",
    "    dataset = pd.rdf = pd.read_csv(\"toy_dataset.txt\", delimiter=';')\n",
    "    date_format = '%Y-%d-%m %H:%M'\n",
    "    dataset['date'] = pd.to_datetime(dataset['date'], format=date_format)\n",
    "    #dataset = dataset.set_index('date')\n",
    "    xED_algorithm(data=dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(breakfast, coffee)</td>\n",
       "      <td>{'numeric': {29115.0: 540.624638729}, 'readabl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(breakfast, coffee, kitchen)</td>\n",
       "      <td>{'numeric': {28710.0: 806.659779586}, 'readabl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(coffee, kitchen, lunch)</td>\n",
       "      <td>{'numeric': {44520.0: 1200.0}, 'readable': {'1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(kitchen, lunch)</td>\n",
       "      <td>{'numeric': {45165.0: 1209.98966938}, 'readabl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(coffee, kitchen)</td>\n",
       "      <td>{'numeric': {28710.0: 806.659779586, 44520.0: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(kitchen,)</td>\n",
       "      <td>{'numeric': {45165.0: 1209.98966938, 28710.0: ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              0  \\\n",
       "0           (breakfast, coffee)   \n",
       "1  (breakfast, coffee, kitchen)   \n",
       "2      (coffee, kitchen, lunch)   \n",
       "3              (kitchen, lunch)   \n",
       "4             (coffee, kitchen)   \n",
       "5                    (kitchen,)   \n",
       "\n",
       "                                                   1  \n",
       "0  {'numeric': {29115.0: 540.624638729}, 'readabl...  \n",
       "1  {'numeric': {28710.0: 806.659779586}, 'readabl...  \n",
       "2  {'numeric': {44520.0: 1200.0}, 'readable': {'1...  \n",
       "3  {'numeric': {45165.0: 1209.98966938}, 'readabl...  \n",
       "4  {'numeric': {28710.0: 806.659779586, 44520.0: ...  \n",
       "5  {'numeric': {45165.0: 1209.98966938, 28710.0: ...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dataset = pd.rdf = pd.read_csv(\"toy_dataset.txt\", delimiter=';')\n",
    "date_format = '%Y-%d-%m %H:%M'\n",
    "dataset['date'] = pd.to_datetime(dataset['date'], format=date_format)\n",
    "#dataset = dataset.set_index('date')\n",
    "p = xED_algorithm(data=dataset)\n",
    "\n",
    "for i in p.keys():\n",
    "    pd.DataFrame(list(p[i].items()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
